{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "import components\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the WMT14 dataset for German-English translation\n",
    "dataset = load_dataset('wmt14', 'de-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, we will train on a small segment of the dataset as we will be working locally. \n",
    "# We will figure out the parameters and then train on the full set in the cloud. \n",
    "\n",
    "# Take a small subset for experimentation\n",
    "small_train_dataset = dataset['train'].select(range(20000))\n",
    "small_val_dataset = dataset['validation'].select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we are following the original `Attention is all you need paper` we will use Byte-Pair Encoding\n",
    "from tokenizers import ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be training our own BPE tokenizer for this task. \n",
    "\n",
    "with open('train_texts.txt', 'w', encoding='utf-8') as f:\n",
    "\n",
    "    for example in tqdm(dataset['train']):\n",
    "        f.write(example['translation']['de'] + '\\n')\n",
    "        f.write(example['translation']['en'] + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now train a BPE tokenizer\n",
    "bpe_tokenizer = ByteLevelBPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_tokenizer.train(\n",
    "    files=['train_texts.txt'],\n",
    "    vocab_size=37000,\n",
    "    min_frequency=2,\n",
    "    special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tokenizer\n",
    "save_directory = 'bpe_tokenizer'\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "bpe_tokenizer.save_model('bpe_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"bpe_tokenizer/vocab.json\",\n",
    "    \"bpe_tokenizer/merges.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[789, 423, 328, 3010, 18]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Test the tokenizer\n",
    "print(tokenizer.encode(\"Das ist ein Beispiel.\").ids)\n",
    "# Should return something like ['<s>', 'Das', 'ist', 'ein', 'Beispiel', '</s>']\n",
    "\n",
    "print(tokenizer.token_to_id(\"</s>\"))\n",
    "# Should return a valid token ID for '</s>'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the tokenization pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "\n",
    "    # Extract German and English sentences from the list of dictionaries\n",
    "    src_texts = [example['de'] for example in examples['translation']]\n",
    "    tgt_texts = [example['en'] for example in examples['translation']]\n",
    "\n",
    "    # tokenize src and tgt\n",
    "    src_tokens = tokenizer.encode_batch(src_texts)\n",
    "    tgt_tokens = tokenizer.encode_batch(tgt_texts)\n",
    "\n",
    "    # return dictionary format expected by PyTorch\n",
    "    return {\n",
    "        'input_ids': [[tokenizer.token_to_id('<s>')] + encoding.ids + [tokenizer.token_to_id('</s>')] for encoding in src_tokens],\n",
    "        'attention_mask': [[tokenizer.token_to_id('<pad>')] + encoding.attention_mask + [tokenizer.token_to_id('<pad>')] for encoding in src_tokens],\n",
    "        'labels': [[tokenizer.token_to_id('<s>')] + encoding.ids + [tokenizer.token_to_id('</s>')] for encoding in tgt_tokens]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the data\n",
    "tokenized_train = small_train_dataset.map(tokenize, batched=True)\n",
    "tokenized_val = small_val_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = tokenized_train[98]\n",
    "\n",
    "assert len(example['input_ids']) == len(example['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'de': 'Wiederaufnahme der Sitzungsperiode',\n",
       "  'en': 'Resumption of the session'},\n",
       " 'input_ids': [0, 23062, 17719, 319, 26699, 2],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1],\n",
       " 'labels': [0, 8859, 27958, 304, 280, 9974, 2]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Resumption of the session</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_train[0]['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to write a collate_fn to pad sentences to be of the same size\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(item['input_ids']) for item in batch]\n",
    "    attention_mask = [torch.tensor(item['attention_mask']) for item in batch]\n",
    "    labels = [torch.tensor(item['labels']) for item in batch]\n",
    "\n",
    "    # Pad sequences to the length of the longest sequence in the batch\n",
    "    input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.token_to_id('<pad>'))\n",
    "    attention_mask_padded = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "    labels_padded = pad_sequence(labels, batch_first=True, padding_value=tokenizer.token_to_id('<pad>'))\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids_padded,\n",
    "        'attention_mask': attention_mask_padded,\n",
    "        'labels': labels_padded\n",
    "    }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# create the data loaders\n",
    "train_dl = DataLoader(\n",
    "    tokenized_train, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_dl = DataLoader(\n",
    "    tokenized_val, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: torch.Size([16, 64])\n",
      "Attention Mask: torch.Size([16, 64])\n",
      "Labels: torch.Size([16, 68])\n"
     ]
    }
   ],
   "source": [
    "# Get the first batch from the training DataLoader\n",
    "for batch in train_dl:\n",
    "    print(\"Input IDs:\", batch['input_ids'].shape)\n",
    "    print(\"Attention Mask:\", batch['attention_mask'].shape)\n",
    "    print(\"Labels:\", batch['labels'].shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "def make_std_mask(tgt, pad):\n",
    "    \"Create a mask to hide padding and future words.\"\n",
    "    #print(\"Target (tgt):\", tgt)\n",
    "    \n",
    "    # Padding mask\n",
    "    tgt_padding_mask = (tgt != pad).unsqueeze(1).unsqueeze(2)\n",
    "    #print(\"Padding Mask:\", tgt_padding_mask)\n",
    "    \n",
    "    # Look-ahead mask (subsequent mask)\n",
    "    tgt_seq_len = tgt.size(-1)\n",
    "    look_ahead_mask = torch.triu(torch.ones((1, tgt_seq_len, tgt_seq_len), device=tgt.device), diagonal=1).type_as(tgt_padding_mask.data)\n",
    "    #print(\"Look-Ahead Mask (Subsequent Mask):\", look_ahead_mask)\n",
    "    \n",
    "    # Combined mask\n",
    "    tgt_mask = tgt_padding_mask & (look_ahead_mask == 0)\n",
    "    #print(\"Combined Target Mask:\", tgt_mask)\n",
    "    \n",
    "    return tgt_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentence IDs: [32, 87, 34, 465, 16218, 22524, 385, 280, 4226, 18, 32, 19, 87, 34]\n",
      "Padded Tokenized Sentence Tensor: tensor([[   32,    87,    34,   465, 16218, 22524,   385,   280,  4226,    18,\n",
      "            32,    19,    87,    34,     1,     1,     1,     1,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "# Example English sentence\n",
    "sentence = \"<s>The cat sat on the mat.</s>\"\n",
    "\n",
    "# Tokenize the sentence using your trained tokenizer\n",
    "tgt_tokens = tokenizer.encode(sentence)\n",
    "tgt_token_ids = tgt_tokens.ids  # Get the list of token IDs\n",
    "print(\"Tokenized Sentence IDs:\", tgt_token_ids)\n",
    "\n",
    "# Convert the token IDs to a tensor (assuming <pad> token ID is 0)\n",
    "tgt_tensor = torch.tensor([tgt_token_ids + [tokenizer.token_to_id('<pad>')] * (20 - len(tgt_token_ids))])  # Pad to length 10\n",
    "print(\"Padded Tokenized Sentence Tensor:\", tgt_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ True, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False],\n",
       "          [ True,  True, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False],\n",
       "          [ True,  True,  True, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "           False, False, False, False, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           False, False, False, False, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True, False, False, False, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True, False, False, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True, False, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True, False, False, False, False, False, False]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_std_mask(tgt_tensor, tokenizer.token_to_id('<pad>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ace007w2) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7506d453b73347969066e3e8d4fffcab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficient-grass-1</strong> at: <a href='https://wandb.ai/dominic-l-culver/transformer-translator/runs/ace007w2' target=\"_blank\">https://wandb.ai/dominic-l-culver/transformer-translator/runs/ace007w2</a><br/> View project at: <a href='https://wandb.ai/dominic-l-culver/transformer-translator' target=\"_blank\">https://wandb.ai/dominic-l-culver/transformer-translator</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_151006-ace007w2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ace007w2). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0960bb42c1438a84928042e281ea0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011176713433168414, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dominicculver/machine_learning/projects/transformers_based_translator/wandb/run-20240827_152413-t5m3pg1h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dominic-l-culver/transformer-translator/runs/t5m3pg1h' target=\"_blank\">elated-butterfly-2</a></strong> to <a href='https://wandb.ai/dominic-l-culver/transformer-translator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dominic-l-culver/transformer-translator' target=\"_blank\">https://wandb.ai/dominic-l-culver/transformer-translator</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dominic-l-culver/transformer-translator/runs/t5m3pg1h' target=\"_blank\">https://wandb.ai/dominic-l-culver/transformer-translator/runs/t5m3pg1h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dominic-l-culver/transformer-translator/runs/t5m3pg1h?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2e7427610>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# initialize wandb\n",
    "wandb.init(project='transformer-translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model config\n",
    "model_config ={\n",
    "    'd_model': 512, \n",
    "    'num_heads': 8,\n",
    "    'num_encoder_layers': 6, \n",
    "    'num_decoder_layers': 6,\n",
    "    'd_ff': 2048,\n",
    "    'dropout': 0.1, \n",
    "    'src_vocab': tokenizer.get_vocab_size(), \n",
    "    'tgt_vocab': tokenizer.get_vocab_size()\n",
    "}\n",
    "d_model = 512  # Model dimension\n",
    "num_heads = 8  # Number of attention heads\n",
    "num_encoder_layers = 6  # Number of encoder layers\n",
    "num_decoder_layers = 6  # Number of decoder layers\n",
    "d_ff = 2048  # Dimension of feedforward layers\n",
    "dropout = 0.1  # Dropout rate\n",
    "\n",
    "vocab_size = tokenizer.get_vocab_size()  # Vocabulary size from your tokenizer\n",
    "\n",
    "# Initialize the encoder, decoder, and the full model\n",
    "encoder = components.Encoder(num_encoder_layers, num_heads, d_model, d_ff, dropout)\n",
    "decoder = components.Decoder(num_decoder_layers, num_heads, d_model, d_ff, dropout)\n",
    "src_embed = nn.Sequential(nn.Embedding(vocab_size, d_model), components.PositionalEncoding(d_model, dropout))\n",
    "tgt_embed = nn.Sequential(nn.Embedding(vocab_size, d_model), components.PositionalEncoding(d_model, dropout))\n",
    "generator = components.Generator(d_model, vocab_size)\n",
    "\n",
    "# Initialize the EncoderDecoder model\n",
    "model = components.EncoderDecoder(encoder, decoder, src_embed, tgt_embed, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create learning rate scheduler, following `Attention is All You Need` for now. \n",
    "# lr = d_model ** (-0.5) * min(step_num ** (-0.5), step_num * warmup_steps ** (-1.5))\n",
    "warmup_steps = 4000\n",
    "\n",
    "def get_lr(step_num):\n",
    "    return d_model ** -0.5 * min(step_num ** -0.5, step_num * warmup_steps ** -1.5)\n",
    "\n",
    "\n",
    "# initialize optimizer, criterion\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.token_to_id('<pad>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (encoder_blocks): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (mha): MultiHeadAttention(\n",
       "          (query_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (output_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ffn): PositionwiseFFN(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0-5): 6 x DecoderLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (query_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (output_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (src_attn): MultiHeadAttention(\n",
       "          (query_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (output_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ffn): PositionwiseFFN(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layernorms): ModuleList(\n",
       "          (0-2): 3 x LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (src_embed): Sequential(\n",
       "    (0): Embedding(37000, 512)\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (tgt_embed): Sequential(\n",
       "    (0): Embedding(37000, 512)\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=512, out_features=37000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0,\n",
       " 'betas': (0.9, 0.98),\n",
       " 'eps': 1e-09,\n",
       " 'weight_decay': 0.01,\n",
       " 'amsgrad': False,\n",
       " 'foreach': None,\n",
       " 'maximize': False,\n",
       " 'capturable': False,\n",
       " 'differentiable': False,\n",
       " 'fused': None}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a211d7aed940649fc737012d4234c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch: 1:   0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# Number of epochs to train\n",
    "num_epochs = 5\n",
    "step_num = 0\n",
    "pad_token_id = tokenizer.token_to_id('<pad>')\n",
    "\n",
    "# log hyperparameters\n",
    "hyperparameters = model_config.copy()\n",
    "hyperparameters['num_epochs'] = num_epochs\n",
    "hyperparameters['batch_size'] = train_dl.batch_size\n",
    "hyperparameters['initial_lr'] = 0\n",
    "hyperparameters['warmup_steps'] = warmup_steps\n",
    "hyperparameters['betas'] = optimizer.defaults['betas']\n",
    "hyperparameters['eps'] = optimizer.defaults['eps']\n",
    "hyperparameters['model'] = model.__class__.__name__\n",
    "\n",
    "\n",
    "wandb.config.update(hyperparameters)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dl, desc=f\"Training Epoch: {epoch + 1}\"):\n",
    "        step_num += 1\n",
    "\n",
    "        # adjust the learning rate according to the schedule\n",
    "        lr = get_lr(step_num)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device).unsqueeze(1).unsqueeze(2)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "\n",
    "        # shift the target token ids for the decoder input\n",
    "        tgt_input = labels[:, :-1]\n",
    "        tgt_y = labels[:, 1:]\n",
    "\n",
    "        # create the target mask (combining padding and look-ahead masks)\n",
    "        tgt_mask = make_std_mask(tgt_input, pad_token_id)\n",
    "\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(src=input_ids, tgt=tgt_input, src_mask=attention_mask, tgt_mask=tgt_mask)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_y.reshape(-1))\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # log the learning rate and training loss to wandb\n",
    "        wandb.log({\n",
    "            'train_loss': loss.item(),\n",
    "            'learning_rate': lr, \n",
    "            'step': step_num,\n",
    "            'epoch': epoch + 1,\n",
    "            })\n",
    "    \n",
    "    avg_loss = total_train_loss / len(train_dl)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dl:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device).unsqueeze(1).unsqueeze(2)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            tgt_input = labels[:, :-1]\n",
    "            tgt_y = labels[:, 1:]\n",
    "\n",
    "            tgt_mask = make_std_mask(tgt_input, pad_token_id)\n",
    "\n",
    "            logits = model(input_ids, tgt_input, attention_mask, tgt_mask)\n",
    "            loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_y.reshape(-1))\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dl)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # log validation loss to wandb\n",
    "    wandb.log({\n",
    "        'val_loss': avg_val_loss, \n",
    "        'epoch': epoch + 1\n",
    "    })\n",
    "\n",
    "# finish the wandb run\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check on a few german sentences\n",
    "\n",
    "model.eval()\n",
    "\n",
    "num_examples = 5\n",
    "examples = []\n",
    "for i in range(num_examples):\n",
    "    examples.append(tokenized_val[i])\n",
    "\n",
    "def decode_tokens(tokens, tokenizer):\n",
    "    return tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "\n",
    "# perform inference\n",
    "with torch.no_grad():\n",
    "    for i, src in enumerate(examples):\n",
    "\n",
    "        # convert to tensor and move to device\n",
    "        src_tensor = torch.tensor(src['input_ids']).unsqueeze(0).to(device)\n",
    "        attention_mask = (src_tensor != pad_token_id).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        print(f\"src_tensor shape: {src_tensor.shape}\")\n",
    "        print(f\"attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "        tgt_tensor = torch.tensor([tokenizer.token_to_id('<s>')]).unsqueeze(0).to(device)\n",
    "\n",
    "        for _ in range(100):  # limit the length of the generated sequence for now at least...\n",
    "            # create the tgt_mask\n",
    "            tgt_mask = make_std_mask(tgt_tensor, pad_token_id)\n",
    "\n",
    "            # run the model\n",
    "            logits = model(src_tensor, tgt_tensor, attention_mask, tgt_mask)\n",
    "\n",
    "            # get the predicted next_token\n",
    "            next_token = logits[:, -1, :].argmax(dim=-1)\n",
    "            # print(f\"Next token predicted: {next_token.item()} (Token: {tokenizer.decode([next_token.item()])})\")\n",
    "\n",
    "            tgt_tensor = torch.cat([tgt_tensor, next_token.unsqueeze(0)], dim=1)\n",
    "\n",
    "            # Check if the predicted token is </s>\n",
    "            if next_token.item() == tokenizer.token_to_id('</s>'):\n",
    "                print(\"End of sentence token encountered, stopping inference.\")\n",
    "                break\n",
    "\n",
    "        # decode the source and target\n",
    "        src_sentence = decode_tokens(src['input_ids'], tokenizer=tokenizer)\n",
    "        tgt_sentence = decode_tokens(tgt_tensor.squeeze().tolist(), tokenizer)\n",
    "        actual_tgt = src['translation']['en']\n",
    "\n",
    "        print(f\"German: {src_sentence}\")\n",
    "        print(f\"Actual translation: {actual_tgt}\")\n",
    "        print(f\"NMT: {tgt_sentence}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
