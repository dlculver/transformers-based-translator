{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "import components\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download and inspect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the WMT14 dataset for German-English translation\n",
    "dataset = load_dataset('wmt14', 'de-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 4508785\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 3003\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'de': 'Heute möchte ich Sie bitten - das ist auch der Wunsch einiger Kolleginnen und Kollegen -, allen Opfern der Stürme, insbesondere in den verschiedenen Ländern der Europäischen Union, in einer Schweigeminute zu gedenken.',\n",
       "  'en': \"In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\"}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a very small segment for experimentation\n",
    "# Take a small subset for experimentation\n",
    "small_train_dataset = dataset['train'].select(range(20))\n",
    "small_val_dataset = dataset['validation'].select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation'],\n",
       "    num_rows: 20\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we are following the original `Attention is all you need paper` we will use Byte-Pair Encoding\n",
    "from tokenizers import ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"bpe_tokenizer/vocab.json\",\n",
    "    \"bpe_tokenizer/merges.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[789, 423, 328, 3010, 18]\n",
      "['Das', 'Ġist', 'Ġein', 'ĠBeispiel']\n",
      "2\n",
      "Das ist ein Beispiel.\n"
     ]
    }
   ],
   "source": [
    "# Test the tokenizer\n",
    "print(tokenizer.encode(\"Das ist ein Beispiel.\").ids)\n",
    "\n",
    "print([tokenizer.id_to_token(token) for token in tokenizer.encode(\"Das ist ein Beispiel\").ids])\n",
    "# Should return something like ['<s>', 'Das', 'ist', 'ein', 'Beispiel', '</s>']\n",
    "\n",
    "print(tokenizer.token_to_id(\"</s>\"))\n",
    "# Should return a valid token ID for '</s>'\n",
    "\n",
    "print(tokenizer.decode(tokenizer.encode(\"Das ist ein Beispiel.\").ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN_ID = tokenizer.token_to_id('<pad>')\n",
    "BOS_TOKEN_ID = tokenizer.token_to_id('<s>')\n",
    "EOS_TOKEN_ID = tokenizer.token_to_id('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pytorch dataset class\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, bos_token_id: int = BOS_TOKEN_ID, eos_token_id: int = EOS_TOKEN_ID ,pad_token_id:int = PAD_TOKEN_ID, max_length: int = 512):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.bos = bos_token_id\n",
    "        self.eos = eos_token_id\n",
    "        self.pad_token_id = pad_token_id\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_sentence = self.dataset[idx]['translation']['de']\n",
    "        tgt_sentence = self.dataset[idx]['translation']['en']\n",
    "\n",
    "        # tokenize the source and target\n",
    "        src_tokens = self.tokenizer.encode(src_sentence).ids\n",
    "        tgt_tokens = self.tokenizer.encode(tgt_sentence).ids\n",
    "\n",
    "        # pad and truncate\n",
    "        src_tokens = torch.tensor(self.pad_and_truncate(self.add_special_tokens(src_tokens)))\n",
    "        tgt_tokens = torch.tensor(self.pad_and_truncate(self.add_special_tokens(tgt_tokens)))\n",
    "\n",
    "        # # create attention masks\n",
    "        # src_mask = (src_tokens != self.pad_token_id).int()\n",
    "        # tgt_mask = (src_tokens != self.pad_token_id).int()\n",
    "\n",
    "        # # create look ahead mask\n",
    "        # look_ahead_mask = self.create_causal_mask(len(tgt_tokens))\n",
    "\n",
    "\n",
    "        return {\n",
    "            'src_sentence': src_sentence, \n",
    "            'tgt_sentence': tgt_sentence, \n",
    "            'src_tokens': src_tokens,\n",
    "            'tgt_tokens': tgt_tokens,\n",
    "            # 'src_mask': src_mask,\n",
    "            # 'tgt_mask': tgt_mask,\n",
    "            # 'look_ahead_mask': look_ahead_mask,\n",
    "            # 'combined_mask': tgt_mask & look_ahead_mask\n",
    "        }\n",
    "\n",
    "    def pad_and_truncate(self, tokens):\n",
    "        if len(tokens) < self.max_length:\n",
    "            tokens = tokens + [self.pad_token_id] * (self.max_length - len(tokens))\n",
    "        else:\n",
    "            tokens = tokens[:self.max_length]\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def add_special_tokens(self, tokens):\n",
    "        return [self.bos] + tokens + [self.eos]\n",
    "\n",
    "    def create_causal_mask(self, size):\n",
    "        # create an lower triangular matrix for the purposes of look ahead masking\n",
    "        return torch.tril(torch.ones(size, size)).type(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TranslationDataset at 0x28c35f2d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_translation_ds = TranslationDataset(small_train_dataset, tokenizer=tokenizer, pad_token_id=PAD_TOKEN_ID, max_length=30)\n",
    "small_translation_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src_sentence': 'Wiederaufnahme der Sitzungsperiode',\n",
       " 'tgt_sentence': 'Resumption of the session',\n",
       " 'src_tokens': tensor([    0, 23062, 17719,   319, 26699,     2,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]),\n",
       " 'tgt_tokens': tensor([    0,  8859, 27958,   304,   280,  9974,     2,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_translation_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate function for handling masks\n",
    "\n",
    "def create_causal_mask(size):\n",
    "    \"\"\"\n",
    "    Creates a causal mask (look-ahead mask) that prevents attending to future tokens.\n",
    "    size: Length of the sequence.\n",
    "    \"\"\"\n",
    "    attn_shape = (1, size, size)\n",
    "    return torch.tril(torch.ones(attn_shape)).type(torch.uint8)  # Shape: (1, seq_length, seq_length)\n",
    "\n",
    "def create_std_mask(tgt, pad_token_id = PAD_TOKEN_ID):\n",
    "    tgt_mask = (tgt != pad_token_id).unsqueeze(-2)\n",
    "    tgt_mask = tgt_mask & create_causal_mask(tgt.size(-1))\n",
    "    return tgt_mask\n",
    "    \n",
    "def collate_fn(batch, pad_token_id = PAD_TOKEN_ID):\n",
    "    src_batch = torch.stack([item['src_tokens'] for item in batch])\n",
    "    tgt_batch = torch.stack([item['tgt_tokens'] for item in batch])\n",
    "\n",
    "    # create source masks\n",
    "    src_mask = (src_batch != pad_token_id).unsqueeze(-2).int() # shape: (bs, seq_length, 1)\n",
    "    tgt = tgt_batch[:, :-1]\n",
    "    tgt_y = tgt_batch[:, 1:]\n",
    "    tgt_mask = create_std_mask(tgt, pad_token_id=pad_token_id)\n",
    "\n",
    "    return {\n",
    "        'src_tokens': src_batch,\n",
    "        'tgt_input': tgt, \n",
    "        'tgt_output': tgt_y,\n",
    "        'src_mask': src_mask, \n",
    "        'tgt_mask': tgt_mask,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source tokens: torch.Size([4, 30])\n",
      "Target tokens: torch.Size([4, 29])\n",
      "Target output tokens: torch.Size([4, 29])\n",
      "Source mask: torch.Size([4, 1, 30])\n",
      "Target mask: torch.Size([4, 29, 29])\n"
     ]
    }
   ],
   "source": [
    "small_dl = DataLoader(small_translation_ds, collate_fn=collate_fn, batch_size=4)\n",
    "\n",
    "for batch in small_dl:\n",
    "    print(f\"Source tokens:\", batch['src_tokens'].shape)\n",
    "    print(f\"Target tokens:\", batch['tgt_input'].shape)\n",
    "    print(f\"Target output tokens:\", batch['tgt_output'].shape)\n",
    "    print(f\"Source mask:\", batch['src_mask'].shape)\n",
    "    print(f\"Target mask:\", batch['tgt_mask'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating each layer step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Dot-Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import math\n",
    "\n",
    "def scaled_dpa(query, key, value, mask=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Implements scaled dot product attention.\n",
    "    Args:\n",
    "        query: (batch_size, seq_length, dim_k)\n",
    "        key: (batch_size, seq_length, dim_k)\n",
    "        value: (batch_size, seq_length, dim_v)\n",
    "        mask: (batch_size, seq_length) or None\n",
    "        verbose: Boolean default False\n",
    "    Returns:\n",
    "        attention_output: (batch_size, seq_length, dim_v)\n",
    "        attention_weights: (batch_size, seq_length, seq_length)\n",
    "    \"\"\"\n",
    "\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)# (bs, seq_length, seq_length)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Scores shape: {scores.shape}\")\n",
    "    \n",
    "    # apply the mask if necessary\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask==0, float('-inf'))\n",
    "    \n",
    "    # apply softmax to get attention_weights\n",
    "    attention_weights = F.softmax(scores, dim=-1) # (bs, seq_length, seq_length)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Attention weights shape: {attention_weights.shape}\")\n",
    "    \n",
    "    output = torch.matmul(attention_weights, value)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Attention output shape: {output.shape}\")\n",
    "    \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2392, 0.1804, 0.6961, 0.6529, 0.5238],\n",
      "         [0.9352, 0.8517, 0.7265, 0.5549, 0.6761],\n",
      "         [0.2457, 0.7580, 0.4439, 0.8665, 0.5431],\n",
      "         [0.9107, 0.8320, 0.6803, 0.3509, 0.7735],\n",
      "         [0.7935, 0.9095, 0.7763, 0.2147, 0.4681]],\n",
      "\n",
      "        [[0.6411, 0.1835, 0.2692, 0.2813, 0.0872],\n",
      "         [0.8633, 0.0867, 0.4679, 0.4048, 0.2432],\n",
      "         [0.7811, 0.2745, 0.0661, 0.5582, 0.8895],\n",
      "         [0.3523, 0.6299, 0.1040, 0.3558, 0.4313],\n",
      "         [0.5022, 0.8402, 0.7190, 0.9545, 0.9001]],\n",
      "\n",
      "        [[0.4773, 0.1745, 0.9453, 0.6105, 0.0271],\n",
      "         [0.8442, 0.2995, 0.8648, 0.7408, 0.5418],\n",
      "         [0.4132, 0.2033, 0.7128, 0.1794, 0.5770],\n",
      "         [0.3995, 0.0186, 0.3465, 0.3992, 0.6211],\n",
      "         [0.2733, 0.3687, 0.4432, 0.0365, 0.7501]]])\n",
      "tensor([[1, 1, 1, 0, 0],\n",
      "        [1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1]])\n",
      "torch.Size([3, 1, 5])\n",
      "tensor([[[0.2392, 0.1804, 0.6961,   -inf,   -inf],\n",
      "         [0.9352, 0.8517, 0.7265,   -inf,   -inf],\n",
      "         [0.2457, 0.7580, 0.4439,   -inf,   -inf],\n",
      "         [0.9107, 0.8320, 0.6803,   -inf,   -inf],\n",
      "         [0.7935, 0.9095, 0.7763,   -inf,   -inf]],\n",
      "\n",
      "        [[0.6411, 0.1835,   -inf,   -inf,   -inf],\n",
      "         [0.8633, 0.0867,   -inf,   -inf,   -inf],\n",
      "         [0.7811, 0.2745,   -inf,   -inf,   -inf],\n",
      "         [0.3523, 0.6299,   -inf,   -inf,   -inf],\n",
      "         [0.5022, 0.8402,   -inf,   -inf,   -inf]],\n",
      "\n",
      "        [[0.4773, 0.1745, 0.9453, 0.6105, 0.0271],\n",
      "         [0.8442, 0.2995, 0.8648, 0.7408, 0.5418],\n",
      "         [0.4132, 0.2033, 0.7128, 0.1794, 0.5770],\n",
      "         [0.3995, 0.0186, 0.3465, 0.3992, 0.6211],\n",
      "         [0.2733, 0.3687, 0.4432, 0.0365, 0.7501]]])\n"
     ]
    }
   ],
   "source": [
    "# Batch size = 1, Sequence length = 5, Embedding dimension = 4 (d_k)\n",
    "batch_size = 3\n",
    "seq_length = 5\n",
    "\n",
    "# example scores\n",
    "scores = torch.rand(batch_size, seq_length, seq_length)\n",
    "print(scores)\n",
    "\n",
    "# Optional mask\n",
    "mask = torch.tensor([\n",
    "    [1, 1, 1, 0, 0], \n",
    "    [1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 1],\n",
    "])\n",
    "print(mask)\n",
    "\n",
    "mask = mask.unsqueeze(1)\n",
    "print(mask.shape)\n",
    "\n",
    "scores = scores.masked_fill(mask==0, float('-inf'))\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query shape: torch.Size([3, 5, 4])\n",
      "Mask shape: torch.Size([3, 1, 5])\n",
      "Scores shape: torch.Size([3, 5, 5])\n",
      "Attention weights shape: torch.Size([3, 5, 5])\n",
      "Attention output shape: torch.Size([3, 5, 4])\n",
      "Attention Output:\n",
      " tensor([[[0.7508, 0.4054, 0.7349, 0.8111],\n",
      "         [0.7661, 0.3746, 0.7277, 0.8306],\n",
      "         [0.7704, 0.3675, 0.7255, 0.8312],\n",
      "         [0.7645, 0.3797, 0.7282, 0.8224],\n",
      "         [0.7668, 0.3749, 0.7271, 0.8261]],\n",
      "\n",
      "        [[0.4664, 0.5393, 0.6602, 0.6321],\n",
      "         [0.4610, 0.5434, 0.6582, 0.6302],\n",
      "         [0.4570, 0.5465, 0.6567, 0.6288],\n",
      "         [0.5064, 0.5089, 0.6750, 0.6462],\n",
      "         [0.4981, 0.5152, 0.6719, 0.6433]],\n",
      "\n",
      "        [[0.4987, 0.5572, 0.5955, 0.5435],\n",
      "         [0.4959, 0.5118, 0.5700, 0.5925],\n",
      "         [0.4933, 0.5540, 0.5934, 0.5472],\n",
      "         [0.4972, 0.5520, 0.5965, 0.5494],\n",
      "         [0.4833, 0.5198, 0.5692, 0.5846]]], device='mps:0')\n",
      "Attention Weights:\n",
      " tensor([[[0.2759, 0.3859, 0.3383, 0.0000, 0.0000],\n",
      "         [0.2359, 0.4457, 0.3184, 0.0000, 0.0000],\n",
      "         [0.2368, 0.4526, 0.3106, 0.0000, 0.0000],\n",
      "         [0.2552, 0.4270, 0.3178, 0.0000, 0.0000],\n",
      "         [0.2475, 0.4374, 0.3151, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5359, 0.4641, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5419, 0.4581, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5463, 0.4537, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4923, 0.5077, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5014, 0.4986, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1326, 0.1996, 0.2128, 0.2462, 0.2089],\n",
      "         [0.1810, 0.1849, 0.1920, 0.1918, 0.2502],\n",
      "         [0.1497, 0.1989, 0.2082, 0.2402, 0.2031],\n",
      "         [0.1742, 0.1743, 0.1793, 0.2565, 0.2156],\n",
      "         [0.1718, 0.2133, 0.2196, 0.1778, 0.2175]]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# test scaled dpa\n",
    "# Example of how to use scaled_dpa with random tensors\n",
    "\n",
    "# Batch size = 1, Sequence length = 5, Embedding dimension = 4 (d_k)\n",
    "batch_size = 3\n",
    "seq_length = 5\n",
    "embedding_dim = 4\n",
    "\n",
    "# Random queries, keys, and values\n",
    "query = torch.rand(batch_size, seq_length, embedding_dim).to(device)\n",
    "key = torch.rand(batch_size, seq_length, embedding_dim).to(device)\n",
    "value = torch.rand(batch_size, seq_length, embedding_dim).to(device)\n",
    "\n",
    "print(f\"Query shape: {query.shape}\")\n",
    "\n",
    "# Optional mask\n",
    "mask = torch.tensor([\n",
    "    [1, 1, 1, 0, 0], \n",
    "    [1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 1],\n",
    "])\n",
    "mask = mask.unsqueeze(1).to(device)\n",
    "\n",
    "print(f\"Mask shape: {mask.shape}\")\n",
    "\n",
    "# Test scaled_dpa\n",
    "output, attention_weights = scaled_dpa(query, key, value, mask, verbose=True)\n",
    "\n",
    "print(\"Attention Output:\\n\", output)\n",
    "print(\"Attention Weights:\\n\", attention_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores shape: torch.Size([1, 5, 5])\n",
      "Attention weights shape: torch.Size([1, 1, 5, 5])\n",
      "Attention output shape: torch.Size([1, 1, 5, 4])\n",
      "Attention Output:\n",
      " tensor([[[[0.8820, 0.1220, 0.7210, 0.6703],\n",
      "          [0.7771, 0.1815, 0.7095, 0.4776],\n",
      "          [0.7132, 0.2853, 0.7961, 0.6038],\n",
      "          [0.7087, 0.2979, 0.8095, 0.6316],\n",
      "          [0.7119, 0.2903, 0.8018, 0.6166]]]], device='mps:0')\n",
      "Attention Weights:\n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5170, 0.4830, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3403, 0.3395, 0.3202, 0.0000, 0.0000],\n",
      "          [0.3367, 0.2955, 0.3678, 0.0000, 0.0000],\n",
      "          [0.3414, 0.3183, 0.3403, 0.0000, 0.0000]]]], device='mps:0')\n",
      "Padding Mask:\n",
      " tensor([[[[ True,  True,  True, False, False]]]], device='mps:0')\n",
      "Causal Mask:\n",
      " tensor([[1, 0, 0, 0, 0],\n",
      "        [1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1]], device='mps:0', dtype=torch.uint8)\n",
      "Combined Mask:\n",
      " tensor([[[[1, 0, 0, 0, 0],\n",
      "          [1, 1, 0, 0, 0],\n",
      "          [1, 1, 1, 0, 0],\n",
      "          [1, 1, 1, 0, 0],\n",
      "          [1, 1, 1, 0, 0]]]], device='mps:0', dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# testing with mask\n",
    "def create_padding_mask(seq):\n",
    "    \"\"\"\n",
    "    Creates a padding mask (1 for valid tokens, 0 for padding tokens).\n",
    "    seq: Tensor of shape (batch_size, seq_length)\n",
    "    \"\"\"\n",
    "    return (seq != 0).unsqueeze(1).unsqueeze(2)  # Shape: (batch_size, 1, 1, seq_length)\n",
    "\n",
    "def create_causal_mask(size):\n",
    "    \"\"\"\n",
    "    Creates a causal mask (look-ahead mask) that prevents attending to future tokens.\n",
    "    size: Length of the sequence.\n",
    "    \"\"\"\n",
    "    return torch.tril(torch.ones(size, size)).type(torch.uint8)  # Shape: (seq_length, seq_length)\n",
    "\n",
    "# Test scaled_dpa with padding and causal masks\n",
    "\n",
    "# Batch size = 1, Sequence length = 5, Embedding dimension = 4 (d_k)\n",
    "batch_size = 1\n",
    "seq_length = 5\n",
    "embedding_dim = 4\n",
    "\n",
    "# Random queries, keys, and values\n",
    "query = torch.rand(batch_size, seq_length, embedding_dim).to(device)\n",
    "key = torch.rand(batch_size, seq_length, embedding_dim).to(device)\n",
    "value = torch.rand(batch_size, seq_length, embedding_dim).to(device)\n",
    "\n",
    "# Create a random sequence with padding (0 represents padding token)\n",
    "src_tokens = torch.tensor([[1, 2, 3, 0, 0]]).to(device)  # Example with 2 padding tokens\n",
    "\n",
    "# Create a padding mask\n",
    "padding_mask = create_padding_mask(src_tokens).to(device)  # Shape: (batch_size, 1, 1, seq_length)\n",
    "\n",
    "# Create a causal mask (look-ahead mask)\n",
    "causal_mask = create_causal_mask(seq_length).to(device)  # Shape: (seq_length, seq_length)\n",
    "\n",
    "# Combine the masks (for testing both padding and causal masking together)\n",
    "combined_mask = padding_mask & causal_mask.unsqueeze(0).to(device)\n",
    "\n",
    "# Test scaled_dpa with the mask\n",
    "output, attention_weights = scaled_dpa(query, key, value, combined_mask, verbose=True)\n",
    "\n",
    "print(\"Attention Output:\\n\", output)\n",
    "print(\"Attention Weights:\\n\", attention_weights)\n",
    "print(\"Padding Mask:\\n\", padding_mask)\n",
    "print(\"Causal Mask:\\n\", causal_mask)\n",
    "print(\"Combined Mask:\\n\", combined_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads: int, d_model: int, dropout=0.1, verbose=False):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads.\"\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Num heads: {num_heads}\")\n",
    "            print(f\"Embedding dimension: {d_model}\")\n",
    "            print(f\"per head dimension: {self.d_k}\")\n",
    "    \n",
    "        # linear layers to project the inputs to query, key, and value\n",
    "        self.query_linear = nn.Linear(d_model, d_model)\n",
    "        self.key_linear = nn.Linear(d_model, d_model)\n",
    "        self.value_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(p=dropout) \n",
    "        self.output_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # query shape is bs, seq_length, d_model\n",
    "        # key shape is bs, seq_length, d_model\n",
    "        # value shape is bs, d_model, d_model\n",
    "        batch_size = query.size(0)\n",
    "        seq_length = query.size(1)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1) # Same mask applied to all heads. \n",
    "\n",
    "        if self.verbose and mask is not None:\n",
    "            print(f\"Mask shape (after unsqueezing at 1): {mask.shape}\")\n",
    "\n",
    "        # apply linear layers\n",
    "        query = self.query_linear(query)   # shape bs, seq_length, d_model\n",
    "        key = self.key_linear(key) #shape: bs, seq_length, d_model\n",
    "        value = self.value_linear(value) # shape: bs, d_model, d_model\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Query shape: {query.shape}\")\n",
    "            print(f\"Key shape: {key.shape}\")\n",
    "            print(f\"Value shape: {value.shape}\")\n",
    "        \n",
    "        # reshape and split into multiple heads\n",
    "        query = query.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) # (bs, num_heads, seq_length, d_k)\n",
    "        key = key.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) # (bs, num_heads, seq_length, d_k)\n",
    "        value = value.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) #(bs, num_heads, seq_length, d_k)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Shapes after projections for query, key, value...\")\n",
    "            print(f\"{query.shape}, {key.shape}, {value.shape}\")\n",
    "\n",
    "        attn_output, attn_weights = scaled_dpa(query, key, value, mask, verbose = self.verbose)\n",
    "\n",
    "        # we've separated the query key and value into separate heads and then computed the scaled dot-product attention for each head.\n",
    "        # Now we must put them back together. \n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Attention output shape after concat: {attn_output.shape}\")\n",
    "\n",
    "        # apply the final linear layer transformation\n",
    "        output = self.output_linear(attn_output)\n",
    "        if self.verbose:\n",
    "            print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8])\n",
      "unchanged query: tensor([[[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12, 13, 14, 15, 16],\n",
      "         [17, 18, 19, 20, 21, 22, 23, 24],\n",
      "         [25, 26, 27, 28, 29, 30, 31, 32]]], device='mps:0')\n",
      "prior to transpose query: tensor([[[[ 1,  2,  3,  4],\n",
      "          [ 5,  6,  7,  8]],\n",
      "\n",
      "         [[ 9, 10, 11, 12],\n",
      "          [13, 14, 15, 16]],\n",
      "\n",
      "         [[17, 18, 19, 20],\n",
      "          [21, 22, 23, 24]],\n",
      "\n",
      "         [[25, 26, 27, 28],\n",
      "          [29, 30, 31, 32]]]], device='mps:0')\n",
      "transposed query: tensor([[[[ 1,  2,  3,  4],\n",
      "          [ 9, 10, 11, 12],\n",
      "          [17, 18, 19, 20],\n",
      "          [25, 26, 27, 28]],\n",
      "\n",
      "         [[ 5,  6,  7,  8],\n",
      "          [13, 14, 15, 16],\n",
      "          [21, 22, 23, 24],\n",
      "          [29, 30, 31, 32]]]], device='mps:0')\n",
      "torch.Size([1, 2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# visualizing how the transpsoe works\n",
    "batch_size = 1\n",
    "seq_length = 4\n",
    "d_model = 8\n",
    "num_heads = 2\n",
    "d_k = d_model // num_heads\n",
    "query = torch.arange(1, seq_length*d_model + 1).view(batch_size, seq_length, d_model).to(device)\n",
    "print(query.shape)\n",
    "print(f\"unchanged query: {query}\")\n",
    "\n",
    "query = query.view(batch_size, -1, num_heads, d_k)\n",
    "print(f\"prior to transpose query: {query}\")\n",
    "\n",
    "query = query.transpose(1, 2)\n",
    "print(f\"transposed query: {query}\")\n",
    "print(query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directly reshaping query: tensor([[[[ 1,  2,  3,  4],\n",
      "          [ 5,  6,  7,  8],\n",
      "          [ 9, 10, 11, 12],\n",
      "          [13, 14, 15, 16]],\n",
      "\n",
      "         [[17, 18, 19, 20],\n",
      "          [21, 22, 23, 24],\n",
      "          [25, 26, 27, 28],\n",
      "          [29, 30, 31, 32]]]])\n"
     ]
    }
   ],
   "source": [
    "query = torch.arange(1, seq_length*d_model + 1).view(batch_size, seq_length, d_model)\n",
    "\n",
    "query = query.view(batch_size, num_heads, -1, d_k)\n",
    "print(f\"Directly reshaping query: {query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num heads: 8\n",
      "Embedding dimension: 64\n",
      "per head dimension: 8\n",
      "Query shape: torch.Size([1, 5, 64])\n",
      "Key shape: torch.Size([1, 5, 64])\n",
      "Value shape: torch.Size([1, 5, 64])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([1, 8, 5, 8]), torch.Size([1, 8, 5, 8]), torch.Size([1, 8, 5, 8])\n",
      "Scores shape: torch.Size([1, 8, 5, 5])\n",
      "Attention weights shape: torch.Size([1, 8, 5, 5])\n",
      "Attention output shape: torch.Size([1, 8, 5, 8])\n",
      "Attention output shape after concat: torch.Size([1, 5, 64])\n",
      "Output shape: torch.Size([1, 5, 64])\n",
      "Multi-Head Attention Output:\n",
      " tensor([[[ 0.0342, -0.0373, -0.0872, -0.1035,  0.0128,  0.0582,  0.0941,\n",
      "          -0.1134, -0.0748,  0.0916, -0.3390,  0.0679,  0.0456, -0.0932,\n",
      "          -0.0045,  0.2098, -0.3338, -0.3554,  0.2468, -0.1839,  0.1335,\n",
      "          -0.0160,  0.1131, -0.1780,  0.2282, -0.0747,  0.0828,  0.1318,\n",
      "           0.1855, -0.1521,  0.1499,  0.0550, -0.3654, -0.0053, -0.3029,\n",
      "          -0.0588, -0.1206, -0.0415, -0.2343, -0.2576, -0.0776,  0.1186,\n",
      "           0.1868,  0.2194,  0.0628, -0.1036, -0.0615,  0.1492, -0.0236,\n",
      "          -0.5499,  0.1798,  0.1297, -0.0304, -0.0809,  0.0703, -0.1455,\n",
      "           0.3637, -0.1103, -0.0543,  0.1721,  0.1159, -0.0058,  0.0106,\n",
      "          -0.1927],\n",
      "         [ 0.0349, -0.0391, -0.0874, -0.1032,  0.0108,  0.0585,  0.0936,\n",
      "          -0.1122, -0.0717,  0.0908, -0.3395,  0.0686,  0.0431, -0.0925,\n",
      "          -0.0049,  0.2104, -0.3353, -0.3571,  0.2479, -0.1841,  0.1344,\n",
      "          -0.0164,  0.1128, -0.1776,  0.2283, -0.0741,  0.0843,  0.1322,\n",
      "           0.1864, -0.1528,  0.1496,  0.0551, -0.3660, -0.0047, -0.3034,\n",
      "          -0.0601, -0.1186, -0.0436, -0.2347, -0.2578, -0.0796,  0.1174,\n",
      "           0.1886,  0.2184,  0.0615, -0.1039, -0.0594,  0.1505, -0.0224,\n",
      "          -0.5518,  0.1808,  0.1281, -0.0307, -0.0832,  0.0696, -0.1453,\n",
      "           0.3635, -0.1118, -0.0563,  0.1720,  0.1179, -0.0081,  0.0124,\n",
      "          -0.1945],\n",
      "         [ 0.0331, -0.0405, -0.0874, -0.1029,  0.0080,  0.0593,  0.0919,\n",
      "          -0.1132, -0.0708,  0.0908, -0.3405,  0.0674,  0.0413, -0.0912,\n",
      "          -0.0054,  0.2104, -0.3356, -0.3559,  0.2477, -0.1826,  0.1344,\n",
      "          -0.0181,  0.1129, -0.1764,  0.2288, -0.0719,  0.0844,  0.1304,\n",
      "           0.1891, -0.1533,  0.1482,  0.0563, -0.3649, -0.0055, -0.3041,\n",
      "          -0.0592, -0.1201, -0.0468, -0.2370, -0.2591, -0.0793,  0.1180,\n",
      "           0.1896,  0.2210,  0.0617, -0.1025, -0.0595,  0.1497, -0.0208,\n",
      "          -0.5504,  0.1787,  0.1263, -0.0321, -0.0859,  0.0680, -0.1462,\n",
      "           0.3637, -0.1136, -0.0540,  0.1726,  0.1187, -0.0067,  0.0149,\n",
      "          -0.1948],\n",
      "         [ 0.0336, -0.0399, -0.0863, -0.1024,  0.0088,  0.0583,  0.0915,\n",
      "          -0.1134, -0.0715,  0.0927, -0.3395,  0.0696,  0.0430, -0.0914,\n",
      "          -0.0065,  0.2097, -0.3342, -0.3537,  0.2477, -0.1824,  0.1337,\n",
      "          -0.0158,  0.1148, -0.1776,  0.2302, -0.0714,  0.0844,  0.1316,\n",
      "           0.1865, -0.1562,  0.1491,  0.0545, -0.3656, -0.0066, -0.3030,\n",
      "          -0.0590, -0.1182, -0.0445, -0.2323, -0.2590, -0.0811,  0.1167,\n",
      "           0.1860,  0.2215,  0.0609, -0.1004, -0.0596,  0.1498, -0.0197,\n",
      "          -0.5491,  0.1785,  0.1286, -0.0305, -0.0817,  0.0682, -0.1459,\n",
      "           0.3657, -0.1107, -0.0541,  0.1716,  0.1194, -0.0061,  0.0128,\n",
      "          -0.1938],\n",
      "         [ 0.0341, -0.0396, -0.0881, -0.1030,  0.0096,  0.0584,  0.0928,\n",
      "          -0.1143, -0.0694,  0.0919, -0.3390,  0.0679,  0.0422, -0.0917,\n",
      "          -0.0051,  0.2110, -0.3351, -0.3540,  0.2473, -0.1841,  0.1333,\n",
      "          -0.0173,  0.1129, -0.1767,  0.2298, -0.0725,  0.0850,  0.1324,\n",
      "           0.1876, -0.1522,  0.1502,  0.0543, -0.3659, -0.0062, -0.3044,\n",
      "          -0.0603, -0.1189, -0.0425, -0.2350, -0.2587, -0.0794,  0.1168,\n",
      "           0.1871,  0.2192,  0.0608, -0.1042, -0.0586,  0.1511, -0.0235,\n",
      "          -0.5498,  0.1788,  0.1290, -0.0309, -0.0840,  0.0687, -0.1444,\n",
      "           0.3636, -0.1111, -0.0538,  0.1704,  0.1194, -0.0060,  0.0139,\n",
      "          -0.1954]]], device='mps:0', grad_fn=<LinearBackward0>)\n",
      "Attention Weights:\n",
      " torch.Size([1, 8, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# Test MultiHeadAttention with random inputs\n",
    "\n",
    "# Define parameters\n",
    "num_heads = 8\n",
    "d_model = 64\n",
    "seq_length = 5\n",
    "batch_size = 1\n",
    "\n",
    "# Random inputs for query, key, and value\n",
    "query = torch.rand(batch_size, seq_length, d_model).to(device)\n",
    "key = torch.rand(batch_size, seq_length, d_model).to(device)\n",
    "value = torch.rand(batch_size, seq_length, d_model).to(device)\n",
    "\n",
    "# No mask for now (can add later)\n",
    "mask = None\n",
    "\n",
    "# Create MultiHeadAttention object\n",
    "multihead_attn = MultiHeadAttention(num_heads=num_heads, d_model=d_model, verbose=True).to(device)\n",
    "\n",
    "# Pass the inputs through multi-head attention\n",
    "output, attention_weights = multihead_attn(query, key, value, mask)\n",
    "\n",
    "print(\"Multi-Head Attention Output:\\n\", output)\n",
    "print(\"Attention Weights:\\n\", attention_weights.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num heads: 2\n",
      "Embedding dimension: 8\n",
      "per head dimension: 4\n",
      "Mask shape (after unsqueezing at 1): torch.Size([1, 1, 1, 4, 4])\n",
      "Query shape: torch.Size([1, 4, 8])\n",
      "Key shape: torch.Size([1, 4, 8])\n",
      "Value shape: torch.Size([1, 4, 8])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([1, 2, 4, 4]), torch.Size([1, 2, 4, 4]), torch.Size([1, 2, 4, 4])\n",
      "Scores shape: torch.Size([1, 2, 4, 4])\n",
      "Attention weights shape: torch.Size([1, 1, 2, 4, 4])\n",
      "Attention output shape: torch.Size([1, 1, 2, 4, 4])\n",
      "Attention output shape after concat: torch.Size([1, 4, 8])\n",
      "Output shape: torch.Size([1, 4, 8])\n",
      "\n",
      "Multi-Head Attention Output:\n",
      " tensor([[[-0.0394, -0.6741, -0.5478,  0.6813, -0.2002,  0.4032, -0.2712,\n",
      "          -0.0627],\n",
      "         [-0.0315, -0.6545, -0.5068,  0.6890, -0.1760,  0.3843, -0.2150,\n",
      "          -0.0893],\n",
      "         [-0.0510, -0.3125, -0.2862,  0.4699, -0.0667,  0.2310, -0.1487,\n",
      "          -0.0472],\n",
      "         [-0.1830, -0.3611, -0.2747,  0.3585, -0.0836,  0.1900, -0.1640,\n",
      "           0.0555]]], device='mps:0', grad_fn=<LinearBackward0>)\n",
      "Attention Weights:\n",
      " tensor([[[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "           [0.4952, 0.5048, 0.0000, 0.0000],\n",
      "           [0.3614, 0.3297, 0.3089, 0.0000],\n",
      "           [0.3631, 0.3273, 0.3096, 0.0000]],\n",
      "\n",
      "          [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "           [0.5169, 0.4831, 0.0000, 0.0000],\n",
      "           [0.3374, 0.3305, 0.3322, 0.0000],\n",
      "           [0.3396, 0.3293, 0.3310, 0.0000]]]]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Padding Mask:\n",
      " tensor([[[[ True,  True,  True, False]]]], device='mps:0')\n",
      "Causal Mask:\n",
      " tensor([[1, 0, 0, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [1, 1, 1, 0],\n",
      "        [1, 1, 1, 1]], device='mps:0', dtype=torch.uint8)\n",
      "Combined Mask:\n",
      " tensor([[[[1, 0, 0, 0],\n",
      "          [1, 1, 0, 0],\n",
      "          [1, 1, 1, 0],\n",
      "          [1, 1, 1, 0]]]], device='mps:0', dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# Test MultiHeadAttention with a padding mask and causal mask\n",
    "\n",
    "# Define parameters\n",
    "num_heads = 2\n",
    "d_model = 8\n",
    "seq_length = 4\n",
    "batch_size = 1\n",
    "\n",
    "# Random inputs for query, key, and value\n",
    "query = torch.rand(batch_size, seq_length, d_model).to(device)\n",
    "key = torch.rand(batch_size, seq_length, d_model).to(device)\n",
    "value = torch.rand(batch_size, seq_length, d_model).to(device)\n",
    "\n",
    "# Create a random sequence with padding (0 represents padding token)\n",
    "src_tokens = torch.tensor([[1, 2, 3, 0]]).to(device)  # Example with 1 padding token\n",
    "\n",
    "# Create a padding mask\n",
    "padding_mask = create_padding_mask(src_tokens).to(device)  # Shape: (batch_size, 1, 1, seq_length)\n",
    "\n",
    "# Create a causal mask (look-ahead mask)\n",
    "causal_mask = create_causal_mask(seq_length).to(device)  # Shape: (seq_length, seq_length)\n",
    "\n",
    "# Combine the masks (bitwise AND to use both padding and causal masks)\n",
    "combined_mask = padding_mask & causal_mask.unsqueeze(0)\n",
    "combined_mask.to(device)\n",
    "\n",
    "# Create MultiHeadAttention object\n",
    "multihead_attn = MultiHeadAttention(num_heads=num_heads, d_model=d_model, verbose=True).to(device)\n",
    "\n",
    "# Pass the inputs through multi-head attention with a mask\n",
    "output, attention_weights = multihead_attn(query, key, value, combined_mask)\n",
    "\n",
    "print(\"\\nMulti-Head Attention Output:\\n\", output)\n",
    "print(\"Attention Weights:\\n\", attention_weights)\n",
    "print(\"Padding Mask:\\n\", padding_mask)\n",
    "print(\"Causal Mask:\\n\", causal_mask)\n",
    "print(\"Combined Mask:\\n\", combined_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we implement the Encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFFN(nn.Module):\n",
    "    def __init__(self, d_ff: int, d_model: int, dropout: float = 0.1):\n",
    "        super(PositionwiseFFN, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(torch.relu(self.linear1(x))))\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, num_heads: int, d_model: int, d_ff: int, dropout: float = 0.1, verbose: bool = False):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(num_heads=num_heads, d_model=d_model, dropout=dropout, verbose=verbose)\n",
    "        self.ffn = PositionwiseFFN(d_ff=d_ff, d_model=d_model, dropout=dropout)\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        if self.verbose:\n",
    "            print(f\"Input to Encoder Layer: {x.shape}\")\n",
    "        \n",
    "        # Multi-head attention with residual connection and layer normalization\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        if self.verbose:\n",
    "            print(f\"attn_output shape: {attn_output.shape}\")\n",
    "        out1 = self.layernorm1(x + self.dropout(attn_output))\n",
    "\n",
    "        # Feedforward with residual connection and layer normalization\n",
    "        ffn_output = self.ffn(out1)\n",
    "        out2 = self.layernorm2(out1 + self.dropout(ffn_output))  # Fixed: add out1, not x\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Output from Encoder Layer: {out2.shape}\")\n",
    "        \n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding mask: tensor([[[[1, 1, 1, 0]]]], device='mps:0', dtype=torch.int32)\n",
      "Num heads: 2\n",
      "Embedding dimension: 8\n",
      "per head dimension: 4\n",
      "Input to Encoder Layer: torch.Size([1, 4, 8])\n",
      "Mask shape (after unsqueezing at 1): torch.Size([1, 1, 1, 1, 4])\n",
      "Query shape: torch.Size([1, 4, 8])\n",
      "Key shape: torch.Size([1, 4, 8])\n",
      "Value shape: torch.Size([1, 4, 8])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([1, 2, 4, 4]), torch.Size([1, 2, 4, 4]), torch.Size([1, 2, 4, 4])\n",
      "Scores shape: torch.Size([1, 2, 4, 4])\n",
      "Attention weights shape: torch.Size([1, 1, 2, 4, 4])\n",
      "Attention output shape: torch.Size([1, 1, 2, 4, 4])\n",
      "Attention output shape after concat: torch.Size([1, 4, 8])\n",
      "Output shape: torch.Size([1, 4, 8])\n",
      "attn_output shape: torch.Size([1, 4, 8])\n",
      "Output from Encoder Layer: torch.Size([1, 4, 8])\n",
      "\n",
      "Output from Encoder Layer:\n",
      " tensor([[[-0.7413, -1.8561,  0.0692,  1.0786, -0.3384,  1.5060,  0.5964,\n",
      "          -0.3144],\n",
      "         [-0.6385, -1.3609, -0.6182,  0.5870,  0.5405,  1.2521,  1.3690,\n",
      "          -1.1310],\n",
      "         [-0.1527, -1.2015, -0.4480, -0.1967,  0.7025,  2.0160,  0.4996,\n",
      "          -1.2192],\n",
      "         [-1.0402, -1.1565,  0.5690,  0.0532, -0.0960,  0.4520,  2.0752,\n",
      "          -0.8566]]], device='mps:0', grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test EncoderLayer with random inputs\n",
    "\n",
    "# Define parameters\n",
    "num_heads = 2\n",
    "d_model = 8\n",
    "d_ff = 16\n",
    "seq_length = 4\n",
    "batch_size = 1\n",
    "\n",
    "# Random input sequence\n",
    "x = torch.rand(batch_size, seq_length, d_model).to(device)\n",
    "\n",
    "# Create a random padding mask (e.g., if needed)\n",
    "padding_mask = create_padding_mask(torch.tensor([[1, 2, 3, 0]])).to(device)  # Example with padding\n",
    "print(f\"Padding mask: {padding_mask.int()}\")\n",
    "\n",
    "# Create EncoderLayer object\n",
    "encoder_layer = EncoderLayer(num_heads=num_heads, d_model=d_model, d_ff=d_ff, verbose=True).to(device)\n",
    "\n",
    "# Pass the input through the encoder layer\n",
    "output = encoder_layer(x, mask=padding_mask)\n",
    "\n",
    "print(\"\\nOutput from Encoder Layer:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num heads: 2\n",
      "Embedding dimension: 8\n",
      "per head dimension: 4\n",
      "Input to Encoder Layer: torch.Size([1, 4, 8])\n",
      "Mask shape (after unsqueezing at 1): torch.Size([1, 1, 1, 1, 4])\n",
      "Query shape: torch.Size([1, 4, 8])\n",
      "Key shape: torch.Size([1, 4, 8])\n",
      "Value shape: torch.Size([1, 4, 8])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([1, 2, 4, 4]), torch.Size([1, 2, 4, 4]), torch.Size([1, 2, 4, 4])\n",
      "Scores shape: torch.Size([1, 2, 4, 4])\n",
      "Attention weights shape: torch.Size([1, 1, 2, 4, 4])\n",
      "Attention output shape: torch.Size([1, 1, 2, 4, 4])\n",
      "Attention output shape after concat: torch.Size([1, 4, 8])\n",
      "Output shape: torch.Size([1, 4, 8])\n",
      "attn_output shape: torch.Size([1, 4, 8])\n",
      "Output from Encoder Layer: torch.Size([1, 4, 8])\n",
      "Output from encoder layer with padding mask: tensor([[[ 1.4153, -0.0249,  1.6359,  0.3697, -0.8600, -1.1400, -0.4071,\n",
      "          -0.9890],\n",
      "         [-1.3790,  1.2463,  0.9173,  0.0502, -0.7955, -0.8437,  1.4104,\n",
      "          -0.6061],\n",
      "         [ 0.4538, -0.5605,  0.3795, -1.8902,  1.1519,  1.1869,  0.2586,\n",
      "          -0.9800],\n",
      "         [ 0.1595,  0.9940,  0.1927, -1.8283,  0.8965,  0.9565,  0.0032,\n",
      "          -1.3741]]], device='mps:0', grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create a padding mask (0 indicates padding)\n",
    "src_tokens = torch.tensor([[1, 2, 3, 0]]).to(device)  # Example sequence with padding\n",
    "padding_mask = create_padding_mask(src_tokens).to(device)\n",
    "\n",
    "# Test EncoderLayer with padding mask\n",
    "encoder_layer = EncoderLayer(num_heads=2, d_model=8, d_ff=16, dropout=0.1, verbose=True).to(device)\n",
    "x = torch.rand(1, 4, 8).to(device)  # Random input sequence\n",
    "\n",
    "# Pass through the encoder layer with the mask\n",
    "output = encoder_layer(x, mask=padding_mask)\n",
    "print(\"Output from encoder layer with padding mask:\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decoder layer implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, num_heads: int, d_model: int, d_ff: int, dropout: float = 0.1, verbose=False):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(num_heads=num_heads, d_model=d_model, dropout=dropout, verbose=verbose)\n",
    "        self.src_attn = MultiHeadAttention(num_heads=num_heads, d_model=d_model, dropout=dropout, verbose=verbose)\n",
    "        self.ffn = PositionwiseFFN(d_ff=d_ff, d_model=d_model, dropout=dropout)\n",
    "        self.layernorms = nn.ModuleList([nn.LayerNorm(d_model) for _ in range(3)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Input shape x: {x.shape}\")\n",
    "            print(f\"Encoder output shape: {enc_output.shape}\\n\")\n",
    "        # masked self-attention over the target (with look-ahead mask)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Passing through self-attention\")\n",
    "        self_attn_output, _ = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.layernorms[0](x + self.dropout(self_attn_output))\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"\\nPassing Through encoder-decoder attention\")\n",
    "        # encoder-decoder attention over the encoder output (attend to source)\n",
    "        enc_dec_attn_output, _ = self.src_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.layernorms[1](x + self.dropout(enc_dec_attn_output))\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"\\nFinal feedforward of layer\")\n",
    "        # feedforward with residual connection and layer normalization\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.layernorms[2](x + self.dropout(ffn_output))\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\\nOutput shape: {x.shape}\")\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_causal_mask(seq_length):\n",
    "    \"\"\"\n",
    "    Creates a causal mask (look-ahead mask) that prevents attending to future tokens.\n",
    "    size: Length of the sequence.\n",
    "    \"\"\"\n",
    "    return torch.tril(torch.ones(seq_length, seq_length)).type(torch.uint8)  # Shape: (seq_length, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num heads: 2\n",
      "Embedding dimension: 8\n",
      "per head dimension: 4\n",
      "Num heads: 2\n",
      "Embedding dimension: 8\n",
      "per head dimension: 4\n",
      "Input shape x: torch.Size([1, 4, 8])\n",
      "Encoder output shape: torch.Size([1, 4, 8])\n",
      "\n",
      "Passing through self-attention\n",
      "Mask shape (after unsqueezing at 1): torch.Size([1, 1, 4, 4])\n",
      "Query shape: torch.Size([1, 4, 8])\n",
      "Key shape: torch.Size([1, 4, 8])\n",
      "Value shape: torch.Size([1, 4, 8])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([1, 2, 4, 4]), torch.Size([1, 2, 4, 4]), torch.Size([1, 2, 4, 4])\n",
      "Scores shape: torch.Size([1, 2, 4, 4])\n",
      "Attention weights shape: torch.Size([1, 2, 4, 4])\n",
      "Attention output shape: torch.Size([1, 2, 4, 4])\n",
      "Attention output shape after concat: torch.Size([1, 4, 8])\n",
      "Output shape: torch.Size([1, 4, 8])\n",
      "\n",
      "Passing Through encoder-decoder attention\n",
      "Mask shape (after unsqueezing at 1): torch.Size([1, 1, 1, 1, 4])\n",
      "Query shape: torch.Size([1, 4, 8])\n",
      "Key shape: torch.Size([1, 4, 8])\n",
      "Value shape: torch.Size([1, 4, 8])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([1, 2, 4, 4]), torch.Size([1, 2, 4, 4]), torch.Size([1, 2, 4, 4])\n",
      "Scores shape: torch.Size([1, 2, 4, 4])\n",
      "Attention weights shape: torch.Size([1, 1, 2, 4, 4])\n",
      "Attention output shape: torch.Size([1, 1, 2, 4, 4])\n",
      "Attention output shape after concat: torch.Size([1, 4, 8])\n",
      "Output shape: torch.Size([1, 4, 8])\n",
      "\n",
      "Final feedforward of layer\n",
      "\n",
      "Output shape: torch.Size([1, 4, 8])\n",
      "Output from decoder layer: tensor([[[-0.3609, -0.6161, -1.2087, -1.0392,  2.0428,  0.5845, -0.0589,\n",
      "           0.6565],\n",
      "         [-0.4680, -1.5537, -1.0523,  0.8084,  1.3861, -0.6617,  0.5984,\n",
      "           0.9427],\n",
      "         [ 1.1197, -1.1194, -1.7895,  0.9186,  0.6499, -0.1580, -0.4920,\n",
      "           0.8707],\n",
      "         [-0.4378, -0.6701, -1.4852,  0.5869,  2.0996, -0.2726, -0.3043,\n",
      "           0.4834]]], device='mps:0', grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Random input sequence for target (decoder input)\n",
    "tgt = torch.rand(1, 4, 8).to(device)  # (batch_size=1, seq_length=4, d_model=8)\n",
    "\n",
    "# Random encoder output (assuming same dimensions for simplicity)\n",
    "enc_output = torch.rand(1, 4, 8).to(device)\n",
    "\n",
    "# Create masks\n",
    "tgt_mask = create_causal_mask(seq_length=4).unsqueeze(0).to(device)  # Causal mask for target\n",
    "src_mask = create_padding_mask(torch.tensor([[1, 2, 3, 0]])).to(device)  # Padding mask for source\n",
    "\n",
    "# Initialize the decoder layer\n",
    "decoder_layer = DecoderLayer(num_heads=2, d_model=8, d_ff=16, dropout=0.1, verbose=True).to(device)\n",
    "\n",
    "# Pass through the decoder layer\n",
    "output = decoder_layer(tgt, enc_output, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "print(\"Output from decoder layer:\", output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1), :].requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_blocks: int, num_heads: int, d_model: int, d_ff: int, dropout: float = 0.1, verbose: bool = False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_blocks = num_blocks\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # encoder layers\n",
    "        self.encoder_blocks = nn.ModuleList([\n",
    "            EncoderLayer(num_heads=num_heads, d_model=d_model, d_ff=d_ff, dropout=dropout, verbose=verbose) for _ in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "        # final layer normalization layer\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, src_mask = None):\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Input of shape: {x.shape}\")\n",
    "        \n",
    "        for i, block in enumerate(self.encoder_blocks):\n",
    "            if self.verbose:\n",
    "                print(f\"\\n------------ Passing Through Encoder block {i + 1} ----------------\")\n",
    "            \n",
    "            x = block(x, mask=src_mask)\n",
    "\n",
    "        # apply final layer normalization\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"\\nFinal output shape is: {x.shape}\")\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoder.__init__() got an unexpected keyword argument 'max_length'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m src_mask \u001b[38;5;241m=\u001b[39m create_padding_mask(torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m]]))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize the encoder with 2 blocks for testing\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_ff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Pass through the encoder\u001b[39;00m\n\u001b[1;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m encoder(src, src_mask\u001b[38;5;241m=\u001b[39msrc_mask)\n",
      "\u001b[0;31mTypeError\u001b[0m: Encoder.__init__() got an unexpected keyword argument 'max_length'"
     ]
    }
   ],
   "source": [
    "# Random input sequence (batch_size=1, seq_length=4, d_model=8)\n",
    "src = torch.rand(1, 4, 8)\n",
    "\n",
    "# Create a padding mask for the source sequence\n",
    "src_mask = create_padding_mask(torch.tensor([[1, 2, 3, 0]]))\n",
    "\n",
    "# Initialize the encoder with 2 blocks for testing\n",
    "encoder = Encoder(num_blocks=2, num_heads=2, d_model=8, d_ff=16, dropout=0.1, max_length=30, verbose=True)\n",
    "\n",
    "# Pass through the encoder\n",
    "output = encoder(src, src_mask=src_mask)\n",
    "print(\"Final output from encoder:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with actual examples\n",
    "batch_size = 4\n",
    "small_dl = DataLoader(small_translation_ds, batch_size = batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "for batch in small_dl:\n",
    "    print(batch.keys())\n",
    "    src_tokens = batch['src_tokens'].to(device)  # The tokenized source sentences\n",
    "    tgt_input = batch['tgt_input'].to(device)  # The tokenized target sentences\n",
    "    tgt_output = batch['tgt_output'].to(device)\n",
    "    src_mask = batch['src_mask'].to(device)\n",
    "    tgt_mask = batch['tgt_mask'].to(device)\n",
    "\n",
    "    print(f\"Source tokens: {src_tokens.shape}\")\n",
    "    print(f\"tgt_input: {tgt_input.shape}\")\n",
    "    print(f\"tgt_output: {tgt_output.shape}\")\n",
    "    print(f\"src_mask: {src_mask.shape}\")\n",
    "    print(f\"tgt_mask: {tgt_mask.shape}\")\n",
    "\n",
    "    break  # Just getting the first batch for demonstration\n",
    "\n",
    "encoder = Encoder(num_blocks=6, num_heads=8, d_model=512, d_ff=2048, verbose=True).to(device)\n",
    "\n",
    "embedding = nn.Embedding(tokenizer.get_vocab_size(), 512).to(device)\n",
    "pos_encoder = PositionalEncoding(512, dropout=0.1, max_len=512).to(device)\n",
    "\n",
    "for batch in small_dl:\n",
    "    src_tokens = batch['src_tokens'].to(device)\n",
    "    src_mask = batch['src_mask'].to(device)\n",
    "\n",
    "    print(f\"\\nSource token shape: {src_tokens.shape}\")\n",
    "\n",
    "    src_embed = embedding(src_tokens)\n",
    "    src_embed = pos_encoder(src_embed)\n",
    "    encoder_output = encoder(src_embed, src_mask)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_blocks: int, num_heads: int, d_model: int, d_ff: int, dropout: float = 0.1, verbose: bool = True):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder_blocks = nn.ModuleList([\n",
    "            DecoderLayer(num_heads=num_heads, d_model=d_model, d_ff=d_ff, dropout=dropout, verbose=verbose)\n",
    "        ])\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def forward(self, tgt, enc_output, src_mask=None, tgt_mask=None):\n",
    "        for i, block in enumerate(self.decoder_blocks):\n",
    "            if self.verbose:\n",
    "                print(f\"\\n------------- Passing Through Decoder Block {i+1} ----------------\")\n",
    "            tgt = block(tgt, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        return self.layernorm(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 5])\n",
      "torch.Size([4, 5, 5])\n",
      "Num heads: 8\n",
      "Embedding dimension: 512\n",
      "per head dimension: 64\n",
      "Num heads: 8\n",
      "Embedding dimension: 512\n",
      "per head dimension: 64\n",
      "\n",
      "------------- Passing Through Decoder Block 1 ----------------\n",
      "Input shape x: torch.Size([4, 5, 512])\n",
      "Encoder output shape: torch.Size([4, 5, 512])\n",
      "\n",
      "Passing through self-attention\n",
      "Mask shape (after unsqueezing at 1): torch.Size([4, 1, 5, 5])\n",
      "Query shape: torch.Size([4, 5, 512])\n",
      "Key shape: torch.Size([4, 5, 512])\n",
      "Value shape: torch.Size([4, 5, 512])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([4, 8, 5, 64]), torch.Size([4, 8, 5, 64]), torch.Size([4, 8, 5, 64])\n",
      "Scores shape: torch.Size([4, 8, 5, 5])\n",
      "Attention weights shape: torch.Size([4, 8, 5, 5])\n",
      "Attention output shape: torch.Size([4, 8, 5, 64])\n",
      "Attention output shape after concat: torch.Size([4, 5, 512])\n",
      "Output shape: torch.Size([4, 5, 512])\n",
      "\n",
      "Passing Through encoder-decoder attention\n",
      "Mask shape (after unsqueezing at 1): torch.Size([4, 1, 1, 5])\n",
      "Query shape: torch.Size([4, 5, 512])\n",
      "Key shape: torch.Size([4, 5, 512])\n",
      "Value shape: torch.Size([4, 5, 512])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([4, 8, 5, 64]), torch.Size([4, 8, 5, 64]), torch.Size([4, 8, 5, 64])\n",
      "Scores shape: torch.Size([4, 8, 5, 5])\n",
      "Attention weights shape: torch.Size([4, 8, 5, 5])\n",
      "Attention output shape: torch.Size([4, 8, 5, 64])\n",
      "Attention output shape after concat: torch.Size([4, 5, 512])\n",
      "Output shape: torch.Size([4, 5, 512])\n",
      "\n",
      "Final feedforward of layer\n",
      "\n",
      "Output shape: torch.Size([4, 5, 512])\n",
      "Decoder output shape: torch.Size([4, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Mock data for testing\n",
    "batch_size = 4\n",
    "seq_length = 5\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_blocks = 6\n",
    "d_ff = 2048\n",
    "\n",
    "# Random embedded target tokens (already embedded, just mock data)\n",
    "tgt_embed = torch.rand(batch_size, seq_length, d_model)  # (batch_size, seq_length, d_model)\n",
    "\n",
    "# Random encoder output (to simulate the output from the encoder)\n",
    "enc_output = torch.rand(batch_size, seq_length, d_model)  # (batch_size, seq_length, d_model)\n",
    "\n",
    "# Create padding mask (mock data, assume no padding tokens for simplicity)\n",
    "src_mask = torch.ones(batch_size, 1, seq_length)  # Shape: (batch_size, 1, seq_length)\n",
    "print(src_mask.shape)\n",
    "\n",
    "tgt_mask = torch.tril(torch.ones(batch_size, seq_length, seq_length))\n",
    "print(tgt_mask.shape)\n",
    "\n",
    "\n",
    "# Initialize the decoder without embedding\n",
    "decoder = Decoder(num_blocks=num_blocks, num_heads=num_heads, d_model=d_model, d_ff=d_ff, dropout=0.1, verbose=True)\n",
    "\n",
    "# Pass the mock data through the decoder\n",
    "decoder_output = decoder(tgt_embed, enc_output, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "\n",
    "print(\"Decoder output shape:\", decoder_output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translator Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to instantiate an encoder and decoder class and string them together to confirm that everything works together. Than we will abstract and create an Encoder-Decoder sequence to sequence model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Define the linear + softmax step for generating token probabilities.\n",
    "        Layer projects vector on to vocab space and then applys a log_softmax. \n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.log_softmax(self.proj(x), dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num heads: 8\n",
      "Embedding dimension: 512\n",
      "per head dimension: 64\n",
      "Num heads: 8\n",
      "Embedding dimension: 512\n",
      "per head dimension: 64\n",
      "Num heads: 8\n",
      "Embedding dimension: 512\n",
      "per head dimension: 64\n",
      "Num heads: 8\n",
      "Embedding dimension: 512\n",
      "per head dimension: 64\n",
      "Num heads: 8\n",
      "Embedding dimension: 512\n",
      "per head dimension: 64\n",
      "Num heads: 8\n",
      "Embedding dimension: 512\n",
      "per head dimension: 64\n",
      "Num heads: 8\n",
      "Embedding dimension: 512\n",
      "per head dimension: 64\n",
      "Num heads: 8\n",
      "Embedding dimension: 512\n",
      "per head dimension: 64\n",
      "Source tokens: torch.Size([4, 30])\n",
      "Target input tokens: torch.Size([4, 29])\n",
      "Target output tokens: torch.Size([4, 29])\n",
      "Source mask: torch.Size([4, 1, 30])\n",
      "Target mask: torch.Size([4, 29, 29])\n",
      "Input of shape: torch.Size([4, 30, 512])\n",
      "\n",
      "------------ Passing Through Encoder block 1 ----------------\n",
      "Input to Encoder Layer: torch.Size([4, 30, 512])\n",
      "Mask shape (after unsqueezing at 1): torch.Size([4, 1, 1, 30])\n",
      "Query shape: torch.Size([4, 30, 512])\n",
      "Key shape: torch.Size([4, 30, 512])\n",
      "Value shape: torch.Size([4, 30, 512])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([4, 8, 30, 64]), torch.Size([4, 8, 30, 64]), torch.Size([4, 8, 30, 64])\n",
      "Scores shape: torch.Size([4, 8, 30, 30])\n",
      "Attention weights shape: torch.Size([4, 8, 30, 30])\n",
      "Attention output shape: torch.Size([4, 8, 30, 64])\n",
      "Attention output shape after concat: torch.Size([4, 30, 512])\n",
      "Output shape: torch.Size([4, 30, 512])\n",
      "attn_output shape: torch.Size([4, 30, 512])\n",
      "Output from Encoder Layer: torch.Size([4, 30, 512])\n",
      "\n",
      "------------ Passing Through Encoder block 2 ----------------\n",
      "Input to Encoder Layer: torch.Size([4, 30, 512])\n",
      "Mask shape (after unsqueezing at 1): torch.Size([4, 1, 1, 30])\n",
      "Query shape: torch.Size([4, 30, 512])\n",
      "Key shape: torch.Size([4, 30, 512])\n",
      "Value shape: torch.Size([4, 30, 512])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([4, 8, 30, 64]), torch.Size([4, 8, 30, 64]), torch.Size([4, 8, 30, 64])\n",
      "Scores shape: torch.Size([4, 8, 30, 30])\n",
      "Attention weights shape: torch.Size([4, 8, 30, 30])\n",
      "Attention output shape: torch.Size([4, 8, 30, 64])\n",
      "Attention output shape after concat: torch.Size([4, 30, 512])\n",
      "Output shape: torch.Size([4, 30, 512])\n",
      "attn_output shape: torch.Size([4, 30, 512])\n",
      "Output from Encoder Layer: torch.Size([4, 30, 512])\n",
      "\n",
      "------------ Passing Through Encoder block 3 ----------------\n",
      "Input to Encoder Layer: torch.Size([4, 30, 512])\n",
      "Mask shape (after unsqueezing at 1): torch.Size([4, 1, 1, 30])\n",
      "Query shape: torch.Size([4, 30, 512])\n",
      "Key shape: torch.Size([4, 30, 512])\n",
      "Value shape: torch.Size([4, 30, 512])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([4, 8, 30, 64]), torch.Size([4, 8, 30, 64]), torch.Size([4, 8, 30, 64])\n",
      "Scores shape: torch.Size([4, 8, 30, 30])\n",
      "Attention weights shape: torch.Size([4, 8, 30, 30])\n",
      "Attention output shape: torch.Size([4, 8, 30, 64])\n",
      "Attention output shape after concat: torch.Size([4, 30, 512])\n",
      "Output shape: torch.Size([4, 30, 512])\n",
      "attn_output shape: torch.Size([4, 30, 512])\n",
      "Output from Encoder Layer: torch.Size([4, 30, 512])\n",
      "\n",
      "------------ Passing Through Encoder block 4 ----------------\n",
      "Input to Encoder Layer: torch.Size([4, 30, 512])\n",
      "Mask shape (after unsqueezing at 1): torch.Size([4, 1, 1, 30])\n",
      "Query shape: torch.Size([4, 30, 512])\n",
      "Key shape: torch.Size([4, 30, 512])\n",
      "Value shape: torch.Size([4, 30, 512])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([4, 8, 30, 64]), torch.Size([4, 8, 30, 64]), torch.Size([4, 8, 30, 64])\n",
      "Scores shape: torch.Size([4, 8, 30, 30])\n",
      "Attention weights shape: torch.Size([4, 8, 30, 30])\n",
      "Attention output shape: torch.Size([4, 8, 30, 64])\n",
      "Attention output shape after concat: torch.Size([4, 30, 512])\n",
      "Output shape: torch.Size([4, 30, 512])\n",
      "attn_output shape: torch.Size([4, 30, 512])\n",
      "Output from Encoder Layer: torch.Size([4, 30, 512])\n",
      "\n",
      "------------ Passing Through Encoder block 5 ----------------\n",
      "Input to Encoder Layer: torch.Size([4, 30, 512])\n",
      "Mask shape (after unsqueezing at 1): torch.Size([4, 1, 1, 30])\n",
      "Query shape: torch.Size([4, 30, 512])\n",
      "Key shape: torch.Size([4, 30, 512])\n",
      "Value shape: torch.Size([4, 30, 512])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([4, 8, 30, 64]), torch.Size([4, 8, 30, 64]), torch.Size([4, 8, 30, 64])\n",
      "Scores shape: torch.Size([4, 8, 30, 30])\n",
      "Attention weights shape: torch.Size([4, 8, 30, 30])\n",
      "Attention output shape: torch.Size([4, 8, 30, 64])\n",
      "Attention output shape after concat: torch.Size([4, 30, 512])\n",
      "Output shape: torch.Size([4, 30, 512])\n",
      "attn_output shape: torch.Size([4, 30, 512])\n",
      "Output from Encoder Layer: torch.Size([4, 30, 512])\n",
      "\n",
      "------------ Passing Through Encoder block 6 ----------------\n",
      "Input to Encoder Layer: torch.Size([4, 30, 512])\n",
      "Mask shape (after unsqueezing at 1): torch.Size([4, 1, 1, 30])\n",
      "Query shape: torch.Size([4, 30, 512])\n",
      "Key shape: torch.Size([4, 30, 512])\n",
      "Value shape: torch.Size([4, 30, 512])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([4, 8, 30, 64]), torch.Size([4, 8, 30, 64]), torch.Size([4, 8, 30, 64])\n",
      "Scores shape: torch.Size([4, 8, 30, 30])\n",
      "Attention weights shape: torch.Size([4, 8, 30, 30])\n",
      "Attention output shape: torch.Size([4, 8, 30, 64])\n",
      "Attention output shape after concat: torch.Size([4, 30, 512])\n",
      "Output shape: torch.Size([4, 30, 512])\n",
      "attn_output shape: torch.Size([4, 30, 512])\n",
      "Output from Encoder Layer: torch.Size([4, 30, 512])\n",
      "\n",
      "Final output shape is: torch.Size([4, 30, 512])\n",
      "Encoder output: torch.Size([4, 30, 512])\n",
      "\n",
      "------------- Passing Through Decoder Block 1 ----------------\n",
      "Input shape x: torch.Size([4, 29, 512])\n",
      "Encoder output shape: torch.Size([4, 30, 512])\n",
      "\n",
      "Passing through self-attention\n",
      "Mask shape (after unsqueezing at 1): torch.Size([4, 1, 29, 29])\n",
      "Query shape: torch.Size([4, 29, 512])\n",
      "Key shape: torch.Size([4, 29, 512])\n",
      "Value shape: torch.Size([4, 29, 512])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([4, 8, 29, 64]), torch.Size([4, 8, 29, 64]), torch.Size([4, 8, 29, 64])\n",
      "Scores shape: torch.Size([4, 8, 29, 29])\n",
      "Attention weights shape: torch.Size([4, 8, 29, 29])\n",
      "Attention output shape: torch.Size([4, 8, 29, 64])\n",
      "Attention output shape after concat: torch.Size([4, 29, 512])\n",
      "Output shape: torch.Size([4, 29, 512])\n",
      "\n",
      "Passing Through encoder-decoder attention\n",
      "Mask shape (after unsqueezing at 1): torch.Size([4, 1, 1, 30])\n",
      "Query shape: torch.Size([4, 29, 512])\n",
      "Key shape: torch.Size([4, 30, 512])\n",
      "Value shape: torch.Size([4, 30, 512])\n",
      "Shapes after projections for query, key, value...\n",
      "torch.Size([4, 8, 29, 64]), torch.Size([4, 8, 30, 64]), torch.Size([4, 8, 30, 64])\n",
      "Scores shape: torch.Size([4, 8, 29, 30])\n",
      "Attention weights shape: torch.Size([4, 8, 29, 30])\n",
      "Attention output shape: torch.Size([4, 8, 29, 64])\n",
      "Attention output shape after concat: torch.Size([4, 29, 512])\n",
      "Output shape: torch.Size([4, 29, 512])\n",
      "\n",
      "Final feedforward of layer\n",
      "\n",
      "Output shape: torch.Size([4, 29, 512])\n",
      "tensor([[[-11.0492, -10.6461, -11.2758,  ..., -10.6465, -10.5905, -10.3939],\n",
      "         [-11.1698, -10.8735, -10.3730,  ..., -10.3656, -10.4717, -10.3114],\n",
      "         [-11.2496, -11.0432, -11.3370,  ..., -11.0992, -10.8003, -10.3136],\n",
      "         ...,\n",
      "         [-10.3848, -10.4831, -10.1415,  ..., -10.2732,  -9.7248, -11.2804],\n",
      "         [-10.7289, -10.3877, -11.2964,  ...,  -9.7461, -10.8776, -10.9565],\n",
      "         [ -9.9655,  -9.6049, -11.0166,  ..., -11.1836,  -9.4335, -11.9319]],\n",
      "\n",
      "        [[-11.0222, -10.5815, -11.1675,  ..., -10.9906, -10.7679, -10.3805],\n",
      "         [-10.0987, -10.6551, -10.4809,  ..., -11.3256,  -9.9065, -11.5485],\n",
      "         [-10.8435, -10.3098, -10.9130,  ..., -11.8649, -10.7205, -11.4574],\n",
      "         ...,\n",
      "         [ -9.5809, -10.7438, -10.6836,  ..., -10.5378, -10.6958, -11.7706],\n",
      "         [ -9.6939, -10.2982, -11.5796,  ..., -10.0182, -11.1126, -11.3892],\n",
      "         [-10.6928, -10.5761, -11.0443,  ..., -10.9282, -10.8688, -10.8462]],\n",
      "\n",
      "        [[-11.2588, -10.8459, -11.4727,  ..., -10.2347, -10.8565, -10.1818],\n",
      "         [-11.0551, -10.4032, -10.5434,  ..., -11.4331, -10.3670, -11.0382],\n",
      "         [-10.2059, -11.5056, -10.8993,  ..., -12.6624, -11.3115, -11.4546],\n",
      "         ...,\n",
      "         [ -9.8162,  -9.8817, -11.0204,  ..., -11.2838,  -9.3432, -12.3841],\n",
      "         [-10.1165,  -9.8182, -10.7921,  ..., -11.1143,  -9.2365, -12.1321],\n",
      "         [ -9.9885,  -9.4602, -10.9930,  ..., -11.3090,  -9.5328, -11.9507]],\n",
      "\n",
      "        [[-10.8949, -11.0015, -11.5367,  ..., -10.7981, -10.7855, -10.2532],\n",
      "         [-11.2990, -11.4510, -10.2219,  ..., -10.5915, -10.6468, -10.7426],\n",
      "         [-11.4797, -10.2694, -10.0694,  ..., -11.1727, -10.5248, -10.8322],\n",
      "         ...,\n",
      "         [-10.2444,  -9.3766, -10.8948,  ..., -11.2224,  -9.3220, -11.8485],\n",
      "         [-10.0711,  -9.5445, -10.6982,  ..., -11.3596,  -9.5332, -11.6222],\n",
      "         [-10.3342,  -9.3085, -10.6569,  ..., -11.3466,  -9.6313, -11.9568]]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[ 1589,   541,   324,  5136,   569,   280,  3193,   312,  9376,   393,\n",
      "           766,   520,   812,   264,  1679,   304, 16621, 17198,   555,   312,\n",
      "         18932,   918,   286, 20043, 24555,    18,     2,     1,     1],\n",
      "        [   45, 18723, 24499,   280,  9974,   304,   280,   670,  1140, 11599,\n",
      "          5348,   316,   385, 13534,  2791,  6239,  5373,    16,   312,   352,\n",
      "           795,   970,  3411,  1233,   313,  2643,   538,   264,  6923],\n",
      "        [ 5606,   992,    16,   385,   264,  1841,   304,  1459,    18,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [ 1589,   520, 10821,   264,  2263,   385,   484,  2951,   286,   280,\n",
      "          2024,   304,   280,  2371,  2390,  3489,    16,  2173,   484,   725,\n",
      "            17, 20465,    18,     2,     1,     1,     1,     1,     1]])\n",
      "torch.Size([4, 29, 37000])\n",
      "torch.Size([4, 29])\n",
      "torch.Size([4, 29])\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "d_model = 512\n",
    "d_ff = 2048\n",
    "dropout = 0.1\n",
    "num_blocks = 6\n",
    "num_heads = 8\n",
    "max_len = 30\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "small_dl = DataLoader(small_translation_ds, batch_size = batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "embedding = nn.Embedding(tokenizer.get_vocab_size(), d_model)\n",
    "pos_encoder = PositionalEncoding(d_model=d_model, dropout=dropout, max_len=max_len)\n",
    "\n",
    "encoder = Encoder(num_blocks=num_blocks, num_heads=num_heads, d_model=d_model, d_ff=d_ff, dropout=dropout, verbose=True)\n",
    "\n",
    "decoder = Decoder(num_blocks=6, num_heads=8, d_model=d_model, d_ff=d_ff, dropout=dropout, verbose=True)\n",
    "\n",
    "generator = Generator(d_model=d_model, vocab_size=tokenizer.get_vocab_size())\n",
    "\n",
    "for batch in small_dl:\n",
    "    print(f\"Source tokens:\", batch['src_tokens'].shape)\n",
    "    print(f\"Target input tokens:\", batch['tgt_input'].shape)\n",
    "    print(f\"Target output tokens:\", batch['tgt_output'].shape)\n",
    "    print(f\"Source mask:\", batch['src_mask'].shape)\n",
    "    print(f\"Target mask:\", batch['tgt_mask'].shape)\n",
    "\n",
    "    src_tokens = batch['src_tokens']\n",
    "    src_mask = batch['src_mask']\n",
    "    tgt_input = batch['tgt_input']\n",
    "    tgt_output = batch['tgt_output']\n",
    "    src_mask = batch['src_mask']\n",
    "    tgt_mask = batch['tgt_mask']\n",
    "\n",
    "    src_embed = embedding(src_tokens)\n",
    "    src_embed = pos_encoder(src_embed)\n",
    "    encoder_output = encoder(src_embed, src_mask)\n",
    "\n",
    "    print(f\"Encoder output: {encoder_output.shape}\")\n",
    "\n",
    "    tgt_embed = embedding(tgt_input)\n",
    "    tgt_embed = pos_encoder(tgt_embed)\n",
    "    dec_output = decoder(tgt=tgt_embed, enc_output = encoder_output, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "\n",
    "    output = generator(dec_output)\n",
    "    predicted_tokens = torch.argmax(output, dim=-1)\n",
    "\n",
    "    print(output)\n",
    "    print(tgt_output)\n",
    "\n",
    "    print(output.shape)\n",
    "    print(predicted_tokens.shape)\n",
    "    print(tgt_output.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we abstract the above into a EncoderDecoder class. \n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder, generator: Generator, embedding: nn.Embedding, pos_encoder: PositionalEncoding, verbose: bool = False):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.generator = generator\n",
    "        self.embedding = embedding\n",
    "        self.pos_encoder = pos_encoder\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def forward(self, src_tokens, tgt_input, src_mask, tgt_mask):\n",
    "        # Encoder\n",
    "        src_embed = self.embedding(src_tokens)\n",
    "        src_embed = self.pos_encoder(src_embed)\n",
    "        encoder_output = self.encoder(src_embed, src_mask)\n",
    "\n",
    "        # Decoder\n",
    "        tgt_embed = self.embedding(tgt_input)\n",
    "        tgt_embed = self.pos_encoder(tgt_embed)\n",
    "        dec_output = self.decoder(tgt=tgt_embed, enc_output=encoder_output, src_mask=src_mask, tgt_mask = tgt_mask)\n",
    "\n",
    "        output_log_probs = self.generator(dec_output)\n",
    "\n",
    "        return output_log_probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "train_ds = TranslationDataset(dataset['train'].select(range(5000)), tokenizer=tokenizer, bos_token_id=BOS_TOKEN_ID, eos_token_id=EOS_TOKEN_ID, pad_token_id=PAD_TOKEN_ID)\n",
    "val_ds = TranslationDataset(dataset['validation'], tokenizer=tokenizer, bos_token_id=BOS_TOKEN_ID, eos_token_id=EOS_TOKEN_ID, pad_token_id=PAD_TOKEN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "batch_size = 16\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['src_tokens', 'tgt_input', 'tgt_output', 'src_mask', 'tgt_mask'])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dl:\n",
    "    print(batch.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate models\n",
    "\n",
    "# parameters\n",
    "d_model = 512\n",
    "d_ff = 2048\n",
    "dropout = 0.1\n",
    "num_blocks = 6\n",
    "num_heads = 8\n",
    "max_len = 512\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "embedding = nn.Embedding(tokenizer.get_vocab_size(), d_model).to(device)\n",
    "pos_encoder = PositionalEncoding(d_model=d_model, dropout=dropout, max_len=max_len).to(device)\n",
    "encoder = Encoder(num_blocks=num_blocks, num_heads=num_heads, d_model=d_model, d_ff=d_ff, dropout=dropout, verbose=False).to(device)\n",
    "decoder = Decoder(num_blocks=6, num_heads=8, d_model=d_model, d_ff=d_ff, dropout=dropout, verbose=False).to(device)\n",
    "generator = Generator(d_model=d_model, vocab_size=tokenizer.get_vocab_size()).to(device)\n",
    "\n",
    "model = EncoderDecoder(encoder, decoder, generator, embedding, pos_encoder, verbose=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (encoder_blocks): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (mha): MultiHeadAttention(\n",
       "          (query_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (output_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ffn): PositionwiseFFN(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (query_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (output_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (src_attn): MultiHeadAttention(\n",
       "          (query_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (output_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ffn): PositionwiseFFN(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layernorms): ModuleList(\n",
       "          (0-2): 3 x LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=512, out_features=37000, bias=True)\n",
       "  )\n",
       "  (embedding): Embedding(37000, 512)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480cd037cf7047069d67427b65576ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Average training loss:  0.5966\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8c4c919bec4225a0ddadac5234dd96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Average validation loss: 0.3854\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409bb218986342359dbefaa44e8ce4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, Average training loss:  0.3723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcbea2650df4d5ea43be3040293b392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, Average validation loss: 0.3760\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# training loop\n",
    "# optimizer and criterion\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dl):\n",
    "        src_tokens = batch['src_tokens'].to(device)\n",
    "        tgt_input = batch['tgt_input'].to(device)\n",
    "        tgt_output = batch['tgt_output'].to(device)\n",
    "        src_mask = batch['src_mask'].to(device)\n",
    "        tgt_mask = batch['tgt_mask'].to(device)\n",
    "\n",
    "        # print(src_tokens.device)\n",
    "        # print(src_mask.device)\n",
    "\n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_logits = model(src_tokens, tgt_input, src_mask, tgt_mask)\n",
    "\n",
    "        loss = criterion(output_logits.view(-1, output_logits.size(-1)), tgt_output.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dl)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average training loss: {avg_loss: .4f}\")\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dl):\n",
    "            src_tokens = batch['src_tokens'].to(device)\n",
    "            tgt_input = batch['tgt_input'].to(device)\n",
    "            tgt_output = batch['tgt_output'].to(device)\n",
    "            src_mask = batch['src_mask'].to(device)\n",
    "            tgt_mask = batch['tgt_mask'].to(device)\n",
    "\n",
    "            output = model(src_tokens, tgt_input, src_mask, tgt_mask)\n",
    "\n",
    "            loss = criterion(output.view(-1, output.size(-1)), tgt_output.view(-1))\n",
    "            total_val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_dl)\n",
    "    print(F\"Epoch {epoch + 1}/{num_epochs}, Average validation loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'src_sentence': 'Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten',\n",
       "  'tgt_sentence': 'A Republican strategy to counter the re-election of Obama',\n",
       "  'src_tokens': tensor([    0,  2530,  2878, 12244,  8708,  4789,    16,   577,   319,  4755,\n",
       "           3815,   408, 11741,  7738, 27237,     2,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1]),\n",
       "  'tgt_tokens': tensor([    0,    37,  5929,   279,  4024,   313,  7273,   280,   351,    17,\n",
       "           4357,   675,   304, 11741,     2,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1])},\n",
       " {'src_sentence': 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.',\n",
       "  'tgt_sentence': 'Republican leaders justified their policy by the need to combat electoral fraud.',\n",
       "  'src_tokens': tensor([    0,   567, 29354,  6387,   319, 30529, 12897, 20929,  1090,  2346,\n",
       "            437,   319,  5622,    16,   389,  3041,  3502, 27218,   386, 12398,\n",
       "             18,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1]),\n",
       "  'tgt_tokens': tensor([    0, 25904,  1312,   279,  5465, 14716,   808,  1458,   519,   280,\n",
       "            943,   313,  8810, 18700, 10601,    18,     2,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1])},\n",
       " {'src_sentence': 'Allerdings hält das Brennan Center letzteres für einen Mythos, indem es bekräftigt, dass der Wahlbetrug in den USA seltener ist als die Anzahl der vom Blitzschlag getöteten Menschen.',\n",
       "  'tgt_sentence': 'However, the Brennan Centre considers this a myth, stating that electoral fraud is rarer in the United States than the number of people killed by lightning.',\n",
       "  'src_tokens': tensor([    0,  8067,  9096,   384, 13181,   279,  7277, 13557,   268,   430,\n",
       "            719, 25411,   394,    16,  3623,   531, 21506,    16,   521,   319,\n",
       "           3041,  3502, 27218,   286,   389,  2821, 10610,   262,   423,   475,\n",
       "            317,  5697,   319,  1194, 35674,  4968,  1423,   365,  9984,  1228,\n",
       "             18,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1]),\n",
       "  'tgt_tokens': tensor([    0,  2395,    16,   280, 13181,   279,  6785, 16453,   484,   264,\n",
       "          19725,    16, 24799,   393, 18700, 10601,   326,   409,   285,   262,\n",
       "            286,   280,  2713,  1162,  1189,   280,  1679,   304,  1120, 14608,\n",
       "            519,  3772,  4097,    18,     2,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1])},\n",
       " {'src_sentence': 'Die Rechtsanwälte der Republikaner haben in 10 Jahren in den USA übrigens nur 300 Fälle von Wahlbetrug verzeichnet.',\n",
       "  'tgt_sentence': 'Indeed, Republican lawyers identified only 300 cases of electoral fraud in the United States in a decade.',\n",
       "  'src_tokens': tensor([    0,   567, 31236, 19176,   319, 30529, 12897,   672,   286,  1523,\n",
       "           1802,   286,   389,  2821, 13316,   848,  6139, 11221,   408,  3041,\n",
       "           3502, 27218, 34763,    18,     2,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1]),\n",
       "  'tgt_tokens': tensor([    0,  8342,    16,  5929,   279, 23670, 13771,   962,  6139,  4545,\n",
       "            304, 18700, 10601,   286,   280,  2713,  1162,   286,   264, 15815,\n",
       "             18,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1])},\n",
       " {'src_sentence': 'Eins ist sicher: diese neuen Bestimmungen werden sich negativ auf die Wahlbeteiligung auswirken.',\n",
       "  'tgt_sentence': 'One thing is certain: these new provisions will have a negative impact on voter turn-out.',\n",
       "  'src_tokens': tensor([    0,  1568,    87,   423,  2276,    30,   843,  1777,  6256,   514,\n",
       "            508, 20577,   428,   317,  3041, 29507, 18584,    18,     2,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1]),\n",
       "  'tgt_tokens': tensor([   0, 4342, 4839,  326, 2072,   30, 1032,  874, 6454,  541,  520,  264,\n",
       "          7650, 4926,  385, 2493,  338, 3173,   17,  688,   18,    2,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1])}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if inference works\n",
    "num_examples = 5\n",
    "examples = []\n",
    "for i in range(num_examples):\n",
    "    examples.append(val_ds[i])\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lets implement a greedy decoding\n",
    "def greedy_decoding(model: EncoderDecoder, src_tokens: torch.Tensor, tokenizer, pad_token_id: int = PAD_TOKEN_ID, max_len=100):\n",
    "    model.eval()\n",
    "\n",
    "    # embed the source tokens and create the src_mask\n",
    "    src_tokens.to(device)\n",
    "    src_mask = (src_tokens != pad_token_id).unsqueeze(0).to(device) # shape: (1, seq_length)\n",
    "\n",
    "    src_embed = model.embedding(src_tokens)\n",
    "    src_embed = model.pos_encoder(src_embed)\n",
    "\n",
    "    # store encoder hidden states for the src_tokens\n",
    "    encoder_output = model.encoder(src_tokens, src_mask)\n",
    "\n",
    "    # initizlie target sentence with BOS token\n",
    "    tgt_tokens = torch.tensor([tokenizer.encode(\"<s>\")], dtype=torch.long).to(device)\n",
    "    tgt_mask = torch.ones(1, 1).to(device)\n",
    "\n",
    "    # Autoregressive loop to generate sentence\n",
    "    for _ in range(max_len):\n",
    "        tgt_embed = model.embedding(tgt_tokens)\n",
    "        tgt_embed = model.pos_encoder(tgt_embed)\n",
    "\n",
    "        output_logits = model.decoder(tgt_embed, encoder_output, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "        output_log_probs = model.generator(output_logits)\n",
    "        next_token = torch.argmax(output[:, -1, :], dim=-1).unsqueeze(0)\n",
    "\n",
    "        print()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 512]), torch.Size([1, 512]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokens = val_ds[0]['src_tokens'].unsqueeze(0).to(device)\n",
    "src_sentence = val_ds[0]['src_sentence']\n",
    "src_mask = (src_tokens != PAD_TOKEN_ID).unsqueeze(0).to(device)\n",
    "src_mask.shape, src_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_embed = model.embedding(src_tokens)\n",
    "src_embed = model.pos_encoder(src_embed)\n",
    "encoder_output = model.encoder(src_embed, src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PositionalEncoding(\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_pe = PositionalEncoding(d_model=d_model, dropout=0.1).to(device)\n",
    "temp_pe.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target mask shape: torch.Size([1, 1, 1])\n",
      "Tokens at beginning: tensor([0], device='mps:0')\n",
      "Token embeddings shape: torch.Size([1, 1, 512])\n",
      "None\n",
      "torch.Size([1, 1, 37000])\n",
      "tensor([[[-12.1909,  -6.4150, -10.8411,  ..., -12.9068, -13.2837, -12.5558]]],\n",
      "       device='mps:0', grad_fn=<LogSoftmaxBackward0>)\n",
      "torch.Size([1])\n",
      "tensor([465], device='mps:0')\n",
      "torch.Size([1])\n",
      "tensor([  0, 465], device='mps:0')\n",
      "target mask shape: torch.Size([1, 2, 2])\n",
      "Tokens at beginning: tensor([  0, 465], device='mps:0')\n",
      "Token embeddings shape: torch.Size([1, 2, 512])\n",
      "None\n",
      "torch.Size([1, 2, 37000])\n",
      "tensor([[[-12.1909,  -6.4150, -10.8411,  ..., -12.9068, -13.2837, -12.5558],\n",
      "         [-13.0627,  -4.6582,  -8.2313,  ..., -12.5624, -13.0358, -11.9611]]],\n",
      "       device='mps:0', grad_fn=<LogSoftmaxBackward0>)\n",
      "torch.Size([1])\n",
      "tensor([791], device='mps:0')\n",
      "torch.Size([2])\n",
      "tensor([  0, 465, 791], device='mps:0')\n",
      "target mask shape: torch.Size([1, 3, 3])\n",
      "Tokens at beginning: tensor([  0, 465, 791], device='mps:0')\n",
      "Token embeddings shape: torch.Size([1, 3, 512])\n",
      "None\n",
      "torch.Size([1, 3, 37000])\n",
      "tensor([[[-12.1909,  -6.4150, -10.8411,  ..., -12.9068, -13.2837, -12.5558],\n",
      "         [-13.0627,  -4.6582,  -8.2313,  ..., -12.5624, -13.0358, -11.9611],\n",
      "         [-13.7497,  -6.2406,  -7.6420,  ..., -13.4335, -14.6987, -12.2625]]],\n",
      "       device='mps:0', grad_fn=<LogSoftmaxBackward0>)\n",
      "torch.Size([1])\n",
      "tensor([326], device='mps:0')\n",
      "torch.Size([3])\n",
      "tensor([  0, 465, 791, 326], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "tgt_tokens = torch.tensor([BOS_TOKEN_ID], dtype=torch.long).to(device)\n",
    "# tgt_mask = torch.ones(1, 1).to(device)\n",
    "\n",
    "for _ in range(50):\n",
    "\n",
    "    # create target mask\n",
    "    tgt_seq_len = tgt_tokens.size(0)\n",
    "    tgt_mask = torch.tril(torch.ones(1, tgt_seq_len, tgt_seq_len)).to(device)\n",
    "    print(f\"target mask shape: {tgt_mask.shape}\")\n",
    "\n",
    "    print(f\"Tokens at beginning: {tgt_tokens}\")\n",
    "    tgt_embed = model.embedding(tgt_tokens).unsqueeze(0)\n",
    "    print(print(f\"Token embeddings shape: {tgt_embed.shape}\"))\n",
    "    tgt_embed = model.pos_encoder(tgt_embed)\n",
    "\n",
    "    output_logits = model.decoder(tgt_embed, encoder_output, src_mask, tgt_mask)\n",
    "    output_log_probs = model.generator(output_logits)\n",
    "    print(output_log_probs.shape)\n",
    "    print(output_log_probs)\n",
    "    next_token = torch.argmax(output_log_probs[:, -1, :], dim=-1)\n",
    "    print(next_token.shape)\n",
    "    print(next_token)\n",
    "    print(tgt_tokens.shape)\n",
    "    # append next\n",
    "    tgt_tokens = torch.cat([tgt_tokens, next_token])\n",
    "    print(tgt_tokens)\n",
    "    \n",
    "    if _ == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([897])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
